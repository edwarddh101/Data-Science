





<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
  <link rel="dns-prefetch" href="https://github.githubassets.com">
  <link rel="dns-prefetch" href="https://avatars0.githubusercontent.com">
  <link rel="dns-prefetch" href="https://avatars1.githubusercontent.com">
  <link rel="dns-prefetch" href="https://avatars2.githubusercontent.com">
  <link rel="dns-prefetch" href="https://avatars3.githubusercontent.com">
  <link rel="dns-prefetch" href="https://github-cloud.s3.amazonaws.com">
  <link rel="dns-prefetch" href="https://user-images.githubusercontent.com/">



  <link crossorigin="anonymous" media="all" integrity="sha512-UDS3MR1FfvqHmqZAs2MWSDCWPwLemVRLqCwld4/zfwH0vhv7I6RYmDnMnNAVQKP1YYvqnccOCH4iOhFaUUyrjw==" rel="stylesheet" href="https://github.githubassets.com/assets/frameworks-2e9090135c22aad5f56c2f72dcba7880.css" />
  
    <link crossorigin="anonymous" media="all" integrity="sha512-D8GUhgLn0Pm94+eZHS2+GVyUSkcIQCn86Is/aPo/SqDdh84zzgsUc3pYlfSvK7YJvxqihMWsJET2Tsc6QOD5Ow==" rel="stylesheet" href="https://github.githubassets.com/assets/github-e0bb7eeb3d3f55bf57453459bf0da4e8.css" />
    
    
    
    

  <meta name="viewport" content="width=device-width">
  
  <title>interview-prep/Model_Comparison_Guide.md at master ¬∑ GalvanizeDataScience/interview-prep</title>
    <meta name="description" content="Contribute to GalvanizeDataScience/interview-prep development by creating an account on GitHub.">
    <link rel="search" type="application/opensearchdescription+xml" href="/opensearch.xml" title="GitHub">
  <link rel="fluid-icon" href="https://github.com/fluidicon.png" title="GitHub">
  <meta property="fb:app_id" content="1401488693436528">

    <meta name="twitter:image:src" content="https://avatars2.githubusercontent.com/u/5132781?s=400&amp;v=4" /><meta name="twitter:site" content="@github" /><meta name="twitter:card" content="summary" /><meta name="twitter:title" content="GalvanizeDataScience/interview-prep" /><meta name="twitter:description" content="Contribute to GalvanizeDataScience/interview-prep development by creating an account on GitHub." />
    <meta property="og:image" content="https://avatars2.githubusercontent.com/u/5132781?s=400&amp;v=4" /><meta property="og:site_name" content="GitHub" /><meta property="og:type" content="object" /><meta property="og:title" content="GalvanizeDataScience/interview-prep" /><meta property="og:url" content="https://github.com/GalvanizeDataScience/interview-prep" /><meta property="og:description" content="Contribute to GalvanizeDataScience/interview-prep development by creating an account on GitHub." />

  <link rel="assets" href="https://github.githubassets.com/">
  <link rel="web-socket" href="wss://live.github.com/_sockets/VjI6NDM5MzA0NTQwOjE1MWI1NzdlNjlkMmNhODkyMDZjNDIzYWUxMjk4NGI5OTIwNjQ3NjY2ZjZhYTU1N2E3MzZlZmM2ZmU5YzE1NDA=--a196905752448ecfd2de2014f0974d2ea74716a7">
  <meta name="pjax-timeout" content="1000">
  <link rel="sudo-modal" href="/sessions/sudo_modal">
  <meta name="request-id" content="6009:9A74:2DFC5:43931:5D659AA5" data-pjax-transient>


  

  <meta name="selected-link" value="repo_source" data-pjax-transient>

      <meta name="google-site-verification" content="KT5gs8h0wvaagLKAVWq8bbeNwnZZK1r1XQysX3xurLU">
    <meta name="google-site-verification" content="ZzhVyEFwb7w3e0-uOTltm8Jsck2F5StVihD0exw2fsA">
    <meta name="google-site-verification" content="GXs5KoUUkNCoaAZn7wPN-t01Pywp9M3sEjnt_3_ZWPc">

  <meta name="octolytics-host" content="collector.githubapp.com" /><meta name="octolytics-app-id" content="github" /><meta name="octolytics-event-url" content="https://collector.githubapp.com/github-external/browser_event" /><meta name="octolytics-dimension-request_id" content="6009:9A74:2DFC5:43931:5D659AA5" /><meta name="octolytics-dimension-region_edge" content="sea" /><meta name="octolytics-dimension-region_render" content="iad" /><meta name="octolytics-dimension-ga_id" content="" class="js-octo-ga-id" /><meta name="octolytics-dimension-visitor_id" content="7791822652270022510" /><meta name="octolytics-actor-id" content="8853113" /><meta name="octolytics-actor-login" content="edwarddh101" /><meta name="octolytics-actor-hash" content="f60448f2c6aaacc27f96e863797c159f9090df3dbe1b6da1fdacfae3f4107948" />
<meta name="analytics-location" content="/&lt;user-name&gt;/&lt;repo-name&gt;/blob/show" data-pjax-transient="true" />



    <meta name="google-analytics" content="UA-3769691-2">

  <meta class="js-ga-set" name="userId" content="0afd03ed8c2f0453eab999643049a117">

<meta class="js-ga-set" name="dimension1" content="Logged In">



  

      <meta name="hostname" content="github.com">
    <meta name="user-login" content="edwarddh101">

      <meta name="expected-hostname" content="github.com">
    <meta name="js-proxy-site-detection-payload" content="MzE1ZjViMGVhNDdiZDFjN2Y4MDAxYTExNGEyMmYwNTI1N2I5YmQ2MDRjZTMyNzNmMjdkNzMxOTRjZjMyMjg4Y3x7InJlbW90ZV9hZGRyZXNzIjoiNTQuMjQwLjE5Ni4xOTAiLCJyZXF1ZXN0X2lkIjoiNjAwOTo5QTc0OjJERkM1OjQzOTMxOjVENjU5QUE1IiwidGltZXN0YW1wIjoxNTY2OTM5ODIzLCJob3N0IjoiZ2l0aHViLmNvbSJ9">

    <meta name="enabled-features" content="ACTIONS_V2_ON_MARKETPLACE,MARKETPLACE_FEATURED_BLOG_POSTS,MARKETPLACE_INVOICED_BILLING,MARKETPLACE_SOCIAL_PROOF_CUSTOMERS,MARKETPLACE_TRENDING_SOCIAL_PROOF,MARKETPLACE_RECOMMENDATIONS,MARKETPLACE_PENDING_INSTALLATIONS,NOTIFY_ON_BLOCK,RELATED_ISSUES,GHE_CLOUD_TRIAL">

  <meta name="html-safe-nonce" content="1a5c760d60daa15ebb651341ecda247bc6364bbf">

  <meta http-equiv="x-pjax-version" content="db80b986772a400b5c56114c390a8a02">
  

      <link href="https://github.com/GalvanizeDataScience/interview-prep/commits/master.atom?token=ACDRM6JLN4WX3UNQC7I77MF3OLNT6" rel="alternate" title="Recent Commits to interview-prep:master" type="application/atom+xml">

  <meta name="go-import" content="github.com/GalvanizeDataScience/interview-prep git https://github.com/GalvanizeDataScience/interview-prep.git">

  <meta name="octolytics-dimension-user_id" content="5132781" /><meta name="octolytics-dimension-user_login" content="GalvanizeDataScience" /><meta name="octolytics-dimension-repository_id" content="26934610" /><meta name="octolytics-dimension-repository_nwo" content="GalvanizeDataScience/interview-prep" /><meta name="octolytics-dimension-repository_public" content="false" /><meta name="octolytics-dimension-repository_is_fork" content="false" /><meta name="octolytics-dimension-repository_network_root_id" content="26934610" /><meta name="octolytics-dimension-repository_network_root_nwo" content="GalvanizeDataScience/interview-prep" /><meta name="octolytics-dimension-repository_explore_github_marketplace_ci_cta_shown" content="false" />


    <link rel="canonical" href="https://github.com/GalvanizeDataScience/interview-prep/blob/master/review/Model_Comparison_Guide.md" data-pjax-transient>


  <meta name="browser-stats-url" content="https://api.github.com/_private/browser/stats">

  <meta name="browser-errors-url" content="https://api.github.com/_private/browser/errors">

  <link rel="mask-icon" href="https://github.githubassets.com/pinned-octocat.svg" color="#000000">
  <link rel="icon" type="image/x-icon" class="js-site-favicon" href="https://github.githubassets.com/favicon.ico">

<meta name="theme-color" content="#1e2327">



  <meta name="webauthn-auth-enabled" content="true">

  <meta name="webauthn-registration-enabled" content="true">

  <link rel="manifest" href="/manifest.json" crossOrigin="use-credentials">

  </head>

  <body class="logged-in env-production emoji-size-boost page-responsive page-blob">
    

  <div class="position-relative js-header-wrapper ">
    <a href="#start-of-content" tabindex="1" class="p-3 bg-blue text-white show-on-focus js-skip-to-content">Skip to content</a>
    <div id="js-pjax-loader-bar" class="pjax-loader-bar"><div class="progress"></div></div>

    
    
    


          <header class="Header js-details-container Details flex-wrap flex-lg-nowrap p-responsive" role="banner">

    <div class="Header-item d-none d-lg-flex">
      <a class="Header-link" href="https://github.com/" data-hotkey="g d" aria-label="Homepage" data-ga-click="Header, go to dashboard, icon:logo">
  <svg class="octicon octicon-mark-github v-align-middle" height="32" viewBox="0 0 16 16" version="1.1" width="32" aria-hidden="true"><path fill-rule="evenodd" d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0 0 16 8c0-4.42-3.58-8-8-8z"/></svg>
</a>

    </div>

    <div class="Header-item d-lg-none">
      <button class="Header-link btn-link js-details-target" type="button" aria-label="Toggle navigation" aria-expanded="false">
        <svg height="24" class="octicon octicon-three-bars" viewBox="0 0 12 16" version="1.1" width="18" aria-hidden="true"><path fill-rule="evenodd" d="M11.41 9H.59C0 9 0 8.59 0 8c0-.59 0-1 .59-1H11.4c.59 0 .59.41.59 1 0 .59 0 1-.59 1h.01zm0-4H.59C0 5 0 4.59 0 4c0-.59 0-1 .59-1H11.4c.59 0 .59.41.59 1 0 .59 0 1-.59 1h.01zM.59 11H11.4c.59 0 .59.41.59 1 0 .59 0 1-.59 1H.59C0 13 0 12.59 0 12c0-.59 0-1 .59-1z"/></svg>
      </button>
    </div>

    <div class="Header-item Header-item--full flex-column flex-lg-row width-full flex-order-2 flex-lg-order-none mr-0 mr-lg-3 mt-3 mt-lg-0 Details-content--hidden">
        <div class="header-search flex-self-stretch flex-lg-self-auto mr-0 mr-lg-3 mb-3 mb-lg-0 scoped-search site-scoped-search js-site-search position-relative js-jump-to"
  role="combobox"
  aria-owns="jump-to-results"
  aria-label="Search or jump to"
  aria-haspopup="listbox"
  aria-expanded="false"
>
  <div class="position-relative">
    <!-- '"` --><!-- </textarea></xmp> --></option></form><form class="js-site-search-form" role="search" aria-label="Site" data-scope-type="Repository" data-scope-id="26934610" data-scoped-search-url="/GalvanizeDataScience/interview-prep/search" data-unscoped-search-url="/search" action="/GalvanizeDataScience/interview-prep/search" accept-charset="UTF-8" method="get"><input name="utf8" type="hidden" value="&#x2713;" />
      <label class="form-control input-sm header-search-wrapper p-0 header-search-wrapper-jump-to position-relative d-flex flex-justify-between flex-items-center js-chromeless-input-container">
        <input type="text"
          class="form-control input-sm header-search-input jump-to-field js-jump-to-field js-site-search-focus js-site-search-field is-clearable"
          data-hotkey="s,/"
          name="q"
          value=""
          placeholder="Search or jump to‚Ä¶"
          data-unscoped-placeholder="Search or jump to‚Ä¶"
          data-scoped-placeholder="Search or jump to‚Ä¶"
          autocapitalize="off"
          aria-autocomplete="list"
          aria-controls="jump-to-results"
          aria-label="Search or jump to‚Ä¶"
          data-jump-to-suggestions-path="/_graphql/GetSuggestedNavigationDestinations#csrf-token=0miwnTIMEG1+L4ygIKKPLDmeNadhknLa0uouuKV6lVdMjD5KgB5UhhHnB7fa5JVFhHR6BvbiBvUpMxA+E02EOQ=="
          spellcheck="false"
          autocomplete="off"
          >
          <input type="hidden" class="js-site-search-type-field" name="type" >
            <img src="https://github.githubassets.com/images/search-key-slash.svg" alt="" class="mr-2 header-search-key-slash">

            <div class="Box position-absolute overflow-hidden d-none jump-to-suggestions js-jump-to-suggestions-container">
              
<ul class="d-none js-jump-to-suggestions-template-container">
  

<li class="d-flex flex-justify-start flex-items-center p-0 f5 navigation-item js-navigation-item js-jump-to-suggestion" role="option">
  <a tabindex="-1" class="no-underline d-flex flex-auto flex-items-center jump-to-suggestions-path js-jump-to-suggestion-path js-navigation-open p-2" href="">
    <div class="jump-to-octicon js-jump-to-octicon flex-shrink-0 mr-2 text-center d-none">
      <svg height="16" width="16" class="octicon octicon-repo flex-shrink-0 js-jump-to-octicon-repo d-none" title="Repository" aria-label="Repository" viewBox="0 0 12 16" version="1.1" role="img"><path fill-rule="evenodd" d="M4 9H3V8h1v1zm0-3H3v1h1V6zm0-2H3v1h1V4zm0-2H3v1h1V2zm8-1v12c0 .55-.45 1-1 1H6v2l-1.5-1.5L3 16v-2H1c-.55 0-1-.45-1-1V1c0-.55.45-1 1-1h10c.55 0 1 .45 1 1zm-1 10H1v2h2v-1h3v1h5v-2zm0-10H2v9h9V1z"/></svg>
      <svg height="16" width="16" class="octicon octicon-project flex-shrink-0 js-jump-to-octicon-project d-none" title="Project" aria-label="Project" viewBox="0 0 15 16" version="1.1" role="img"><path fill-rule="evenodd" d="M10 12h3V2h-3v10zm-4-2h3V2H6v8zm-4 4h3V2H2v12zm-1 1h13V1H1v14zM14 0H1a1 1 0 0 0-1 1v14a1 1 0 0 0 1 1h13a1 1 0 0 0 1-1V1a1 1 0 0 0-1-1z"/></svg>
      <svg height="16" width="16" class="octicon octicon-search flex-shrink-0 js-jump-to-octicon-search d-none" title="Search" aria-label="Search" viewBox="0 0 16 16" version="1.1" role="img"><path fill-rule="evenodd" d="M15.7 13.3l-3.81-3.83A5.93 5.93 0 0 0 13 6c0-3.31-2.69-6-6-6S1 2.69 1 6s2.69 6 6 6c1.3 0 2.48-.41 3.47-1.11l3.83 3.81c.19.2.45.3.7.3.25 0 .52-.09.7-.3a.996.996 0 0 0 0-1.41v.01zM7 10.7c-2.59 0-4.7-2.11-4.7-4.7 0-2.59 2.11-4.7 4.7-4.7 2.59 0 4.7 2.11 4.7 4.7 0 2.59-2.11 4.7-4.7 4.7z"/></svg>
    </div>

    <img class="avatar mr-2 flex-shrink-0 js-jump-to-suggestion-avatar d-none" alt="" aria-label="Team" src="" width="28" height="28">

    <div class="jump-to-suggestion-name js-jump-to-suggestion-name flex-auto overflow-hidden text-left no-wrap css-truncate css-truncate-target">
    </div>

    <div class="border rounded-1 flex-shrink-0 bg-gray px-1 text-gray-light ml-1 f6 d-none js-jump-to-badge-search">
      <span class="js-jump-to-badge-search-text-default d-none" aria-label="in this repository">
        In this repository
      </span>
      <span class="js-jump-to-badge-search-text-global d-none" aria-label="in all of GitHub">
        All GitHub
      </span>
      <span aria-hidden="true" class="d-inline-block ml-1 v-align-middle">‚Üµ</span>
    </div>

    <div aria-hidden="true" class="border rounded-1 flex-shrink-0 bg-gray px-1 text-gray-light ml-1 f6 d-none d-on-nav-focus js-jump-to-badge-jump">
      Jump to
      <span class="d-inline-block ml-1 v-align-middle">‚Üµ</span>
    </div>
  </a>
</li>

</ul>

<ul class="d-none js-jump-to-no-results-template-container">
  <li class="d-flex flex-justify-center flex-items-center f5 d-none js-jump-to-suggestion p-2">
    <span class="text-gray">No suggested jump to results</span>
  </li>
</ul>

<ul id="jump-to-results" role="listbox" class="p-0 m-0 js-navigation-container jump-to-suggestions-results-container js-jump-to-suggestions-results-container">
  

<li class="d-flex flex-justify-start flex-items-center p-0 f5 navigation-item js-navigation-item js-jump-to-scoped-search d-none" role="option">
  <a tabindex="-1" class="no-underline d-flex flex-auto flex-items-center jump-to-suggestions-path js-jump-to-suggestion-path js-navigation-open p-2" href="">
    <div class="jump-to-octicon js-jump-to-octicon flex-shrink-0 mr-2 text-center d-none">
      <svg height="16" width="16" class="octicon octicon-repo flex-shrink-0 js-jump-to-octicon-repo d-none" title="Repository" aria-label="Repository" viewBox="0 0 12 16" version="1.1" role="img"><path fill-rule="evenodd" d="M4 9H3V8h1v1zm0-3H3v1h1V6zm0-2H3v1h1V4zm0-2H3v1h1V2zm8-1v12c0 .55-.45 1-1 1H6v2l-1.5-1.5L3 16v-2H1c-.55 0-1-.45-1-1V1c0-.55.45-1 1-1h10c.55 0 1 .45 1 1zm-1 10H1v2h2v-1h3v1h5v-2zm0-10H2v9h9V1z"/></svg>
      <svg height="16" width="16" class="octicon octicon-project flex-shrink-0 js-jump-to-octicon-project d-none" title="Project" aria-label="Project" viewBox="0 0 15 16" version="1.1" role="img"><path fill-rule="evenodd" d="M10 12h3V2h-3v10zm-4-2h3V2H6v8zm-4 4h3V2H2v12zm-1 1h13V1H1v14zM14 0H1a1 1 0 0 0-1 1v14a1 1 0 0 0 1 1h13a1 1 0 0 0 1-1V1a1 1 0 0 0-1-1z"/></svg>
      <svg height="16" width="16" class="octicon octicon-search flex-shrink-0 js-jump-to-octicon-search d-none" title="Search" aria-label="Search" viewBox="0 0 16 16" version="1.1" role="img"><path fill-rule="evenodd" d="M15.7 13.3l-3.81-3.83A5.93 5.93 0 0 0 13 6c0-3.31-2.69-6-6-6S1 2.69 1 6s2.69 6 6 6c1.3 0 2.48-.41 3.47-1.11l3.83 3.81c.19.2.45.3.7.3.25 0 .52-.09.7-.3a.996.996 0 0 0 0-1.41v.01zM7 10.7c-2.59 0-4.7-2.11-4.7-4.7 0-2.59 2.11-4.7 4.7-4.7 2.59 0 4.7 2.11 4.7 4.7 0 2.59-2.11 4.7-4.7 4.7z"/></svg>
    </div>

    <img class="avatar mr-2 flex-shrink-0 js-jump-to-suggestion-avatar d-none" alt="" aria-label="Team" src="" width="28" height="28">

    <div class="jump-to-suggestion-name js-jump-to-suggestion-name flex-auto overflow-hidden text-left no-wrap css-truncate css-truncate-target">
    </div>

    <div class="border rounded-1 flex-shrink-0 bg-gray px-1 text-gray-light ml-1 f6 d-none js-jump-to-badge-search">
      <span class="js-jump-to-badge-search-text-default d-none" aria-label="in this repository">
        In this repository
      </span>
      <span class="js-jump-to-badge-search-text-global d-none" aria-label="in all of GitHub">
        All GitHub
      </span>
      <span aria-hidden="true" class="d-inline-block ml-1 v-align-middle">‚Üµ</span>
    </div>

    <div aria-hidden="true" class="border rounded-1 flex-shrink-0 bg-gray px-1 text-gray-light ml-1 f6 d-none d-on-nav-focus js-jump-to-badge-jump">
      Jump to
      <span class="d-inline-block ml-1 v-align-middle">‚Üµ</span>
    </div>
  </a>
</li>

  

<li class="d-flex flex-justify-start flex-items-center p-0 f5 navigation-item js-navigation-item js-jump-to-global-search d-none" role="option">
  <a tabindex="-1" class="no-underline d-flex flex-auto flex-items-center jump-to-suggestions-path js-jump-to-suggestion-path js-navigation-open p-2" href="">
    <div class="jump-to-octicon js-jump-to-octicon flex-shrink-0 mr-2 text-center d-none">
      <svg height="16" width="16" class="octicon octicon-repo flex-shrink-0 js-jump-to-octicon-repo d-none" title="Repository" aria-label="Repository" viewBox="0 0 12 16" version="1.1" role="img"><path fill-rule="evenodd" d="M4 9H3V8h1v1zm0-3H3v1h1V6zm0-2H3v1h1V4zm0-2H3v1h1V2zm8-1v12c0 .55-.45 1-1 1H6v2l-1.5-1.5L3 16v-2H1c-.55 0-1-.45-1-1V1c0-.55.45-1 1-1h10c.55 0 1 .45 1 1zm-1 10H1v2h2v-1h3v1h5v-2zm0-10H2v9h9V1z"/></svg>
      <svg height="16" width="16" class="octicon octicon-project flex-shrink-0 js-jump-to-octicon-project d-none" title="Project" aria-label="Project" viewBox="0 0 15 16" version="1.1" role="img"><path fill-rule="evenodd" d="M10 12h3V2h-3v10zm-4-2h3V2H6v8zm-4 4h3V2H2v12zm-1 1h13V1H1v14zM14 0H1a1 1 0 0 0-1 1v14a1 1 0 0 0 1 1h13a1 1 0 0 0 1-1V1a1 1 0 0 0-1-1z"/></svg>
      <svg height="16" width="16" class="octicon octicon-search flex-shrink-0 js-jump-to-octicon-search d-none" title="Search" aria-label="Search" viewBox="0 0 16 16" version="1.1" role="img"><path fill-rule="evenodd" d="M15.7 13.3l-3.81-3.83A5.93 5.93 0 0 0 13 6c0-3.31-2.69-6-6-6S1 2.69 1 6s2.69 6 6 6c1.3 0 2.48-.41 3.47-1.11l3.83 3.81c.19.2.45.3.7.3.25 0 .52-.09.7-.3a.996.996 0 0 0 0-1.41v.01zM7 10.7c-2.59 0-4.7-2.11-4.7-4.7 0-2.59 2.11-4.7 4.7-4.7 2.59 0 4.7 2.11 4.7 4.7 0 2.59-2.11 4.7-4.7 4.7z"/></svg>
    </div>

    <img class="avatar mr-2 flex-shrink-0 js-jump-to-suggestion-avatar d-none" alt="" aria-label="Team" src="" width="28" height="28">

    <div class="jump-to-suggestion-name js-jump-to-suggestion-name flex-auto overflow-hidden text-left no-wrap css-truncate css-truncate-target">
    </div>

    <div class="border rounded-1 flex-shrink-0 bg-gray px-1 text-gray-light ml-1 f6 d-none js-jump-to-badge-search">
      <span class="js-jump-to-badge-search-text-default d-none" aria-label="in this repository">
        In this repository
      </span>
      <span class="js-jump-to-badge-search-text-global d-none" aria-label="in all of GitHub">
        All GitHub
      </span>
      <span aria-hidden="true" class="d-inline-block ml-1 v-align-middle">‚Üµ</span>
    </div>

    <div aria-hidden="true" class="border rounded-1 flex-shrink-0 bg-gray px-1 text-gray-light ml-1 f6 d-none d-on-nav-focus js-jump-to-badge-jump">
      Jump to
      <span class="d-inline-block ml-1 v-align-middle">‚Üµ</span>
    </div>
  </a>
</li>


    <li class="d-flex flex-justify-center flex-items-center p-0 f5 js-jump-to-suggestion">
      <img src="https://github.githubassets.com/images/spinners/octocat-spinner-128.gif" alt="Octocat Spinner Icon" class="m-2" width="28">
    </li>
</ul>

            </div>
      </label>
</form>  </div>
</div>


      <nav class="d-flex flex-column flex-lg-row flex-self-stretch flex-lg-self-auto" aria-label="Global">
    <a class="Header-link d-block d-lg-none py-2 py-lg-0 border-top border-lg-top-0 border-white-fade-15" data-ga-click="Header, click, Nav menu - item:dashboard:user" aria-label="Dashboard" href="/dashboard">
      Dashboard
</a>
  <a class="js-selected-navigation-item Header-link  mr-0 mr-lg-3 py-2 py-lg-0 border-top border-lg-top-0 border-white-fade-15" data-hotkey="g p" data-ga-click="Header, click, Nav menu - item:pulls context:user" aria-label="Pull requests you created" data-selected-links="/pulls /pulls/assigned /pulls/mentioned /pulls" href="/pulls">
    Pull requests
</a>
  <a class="js-selected-navigation-item Header-link  mr-0 mr-lg-3 py-2 py-lg-0 border-top border-lg-top-0 border-white-fade-15" data-hotkey="g i" data-ga-click="Header, click, Nav menu - item:issues context:user" aria-label="Issues you created" data-selected-links="/issues /issues/assigned /issues/mentioned /issues" href="/issues">
    Issues
</a>
    <div class="mr-0 mr-lg-3 py-2 py-lg-0 border-top border-lg-top-0 border-white-fade-15">
      <a class="js-selected-navigation-item Header-link" data-ga-click="Header, click, Nav menu - item:marketplace context:user" data-octo-click="marketplace_click" data-octo-dimensions="location:nav_bar" data-selected-links=" /marketplace" href="/marketplace">
        Marketplace
</a>      

    </div>

  <a class="js-selected-navigation-item Header-link  mr-0 mr-lg-3 py-2 py-lg-0 border-top border-lg-top-0 border-white-fade-15" data-ga-click="Header, click, Nav menu - item:explore" data-selected-links="/explore /trending /trending/developers /integrations /integrations/feature/code /integrations/feature/collaborate /integrations/feature/ship showcases showcases_search showcases_landing /explore" href="/explore">
    Explore
</a>


    <a class="Header-link d-block d-lg-none mr-0 mr-lg-3 py-2 py-lg-0 border-top border-lg-top-0 border-white-fade-15" href="https://github.com/edwarddh101">
      <img class="avatar" height="20" width="20" alt="@edwarddh101" src="https://avatars0.githubusercontent.com/u/8853113?s=60&amp;v=4" />
      edwarddh101
</a>
    <!-- '"` --><!-- </textarea></xmp> --></option></form><form action="/logout" accept-charset="UTF-8" method="post"><input name="utf8" type="hidden" value="&#x2713;" /><input type="hidden" name="authenticity_token" value="PYRahnKfTLrdoC2KU5J9G4wbV4EVMwackAuV7c6T3yIpYuI2t7mRFU7hcISjm7zVXHrNPL0Ut4we0Jv4e4zOmg==" />
      <button type="submit" class="Header-link mr-0 mr-lg-3 py-2 py-lg-0 border-top border-lg-top-0 border-white-fade-15 d-lg-none btn-link d-block width-full text-left" data-ga-click="Header, sign out, icon:logout" style="padding-left: 2px;">
        <svg class="octicon octicon-sign-out v-align-middle" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M12 9V7H8V5h4V3l4 3-4 3zm-2 3H6V3L2 1h8v3h1V1c0-.55-.45-1-1-1H1C.45 0 0 .45 0 1v11.38c0 .39.22.73.55.91L6 16.01V13h4c.55 0 1-.45 1-1V8h-1v4z"/></svg>
        Sign out
      </button>
</form></nav>

    </div>

    <div class="Header-item Header-item--full flex-justify-center d-lg-none position-relative">
      <div class="css-truncate css-truncate-target width-fit position-absolute left-0 right-0 text-center">
              <svg class="octicon octicon-lock" viewBox="0 0 12 16" version="1.1" width="12" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 13H3v-1h1v1zm8-6v7c0 .55-.45 1-1 1H1c-.55 0-1-.45-1-1V7c0-.55.45-1 1-1h1V4c0-2.2 1.8-4 4-4s4 1.8 4 4v2h1c.55 0 1 .45 1 1zM3.8 6h4.41V4c0-1.22-.98-2.2-2.2-2.2-1.22 0-2.2.98-2.2 2.2v2H3.8zM11 7H2v7h9V7zM4 8H3v1h1V8zm0 2H3v1h1v-1z"/></svg>
    <a class="Header-link" href="/GalvanizeDataScience">GalvanizeDataScience</a>
    /
    <a class="Header-link" href="/GalvanizeDataScience/interview-prep">interview-prep</a>

</div>
    </div>

    <div class="Header-item position-relative d-none d-lg-flex">
      

    </div>

    <div class="Header-item mr-0 mr-lg-3 flex-order-1 flex-lg-order-none">
      

    <a aria-label="You have no unread notifications" class="Header-link notification-indicator position-relative tooltipped tooltipped-s js-socket-channel js-notification-indicator" data-hotkey="g n" data-ga-click="Header, go to notifications, icon:read" data-channel="notification-changed:8853113" href="/notifications">
        <span class="mail-status "></span>
        <svg class="octicon octicon-bell" viewBox="0 0 14 16" version="1.1" width="14" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M14 12v1H0v-1l.73-.58c.77-.77.81-2.55 1.19-4.42C2.69 3.23 6 2 6 2c0-.55.45-1 1-1s1 .45 1 1c0 0 3.39 1.23 4.16 5 .38 1.88.42 3.66 1.19 4.42l.66.58H14zm-7 4c1.11 0 2-.89 2-2H5c0 1.11.89 2 2 2z"/></svg>
</a>
    </div>


    <div class="Header-item position-relative d-none d-lg-flex">
      <details class="details-overlay details-reset">
  <summary class="Header-link"
      aria-label="Create new‚Ä¶"
      data-ga-click="Header, create new, icon:add">
    <svg class="octicon octicon-plus" viewBox="0 0 12 16" version="1.1" width="12" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M12 9H7v5H5V9H0V7h5V2h2v5h5v2z"/></svg> <span class="dropdown-caret"></span>
  </summary>
  <details-menu class="dropdown-menu dropdown-menu-sw">
    
<a role="menuitem" class="dropdown-item" href="/new" data-ga-click="Header, create new repository">
  New repository
</a>

  <a role="menuitem" class="dropdown-item" href="/new/import" data-ga-click="Header, import a repository">
    Import repository
  </a>

<a role="menuitem" class="dropdown-item" href="https://gist.github.com/" data-ga-click="Header, create new gist">
  New gist
</a>

  <a role="menuitem" class="dropdown-item" href="/organizations/new" data-ga-click="Header, create new organization">
    New organization
  </a>


  <div role="none" class="dropdown-divider"></div>
  <div class="dropdown-header">
    <span title="GalvanizeDataScience/interview-prep">This repository</span>
  </div>
    <a role="menuitem" class="dropdown-item" href="/GalvanizeDataScience/interview-prep/issues/new" data-ga-click="Header, create new issue" data-skip-pjax>
      New issue
    </a>


  </details-menu>
</details>

    </div>

    <div class="Header-item position-relative mr-0 d-none d-lg-flex">
      
<details class="details-overlay details-reset">
  <summary class="Header-link"
    aria-label="View profile and more"
    data-ga-click="Header, show menu, icon:avatar">
    <img alt="@edwarddh101" class="avatar" src="https://avatars3.githubusercontent.com/u/8853113?s=40&amp;v=4" height="20" width="20">
    <span class="dropdown-caret"></span>
  </summary>
  <details-menu class="dropdown-menu dropdown-menu-sw mt-2" style="width: 180px">
    <div class="header-nav-current-user css-truncate"><a role="menuitem" class="no-underline user-profile-link px-3 pt-2 pb-2 mb-n2 mt-n1 d-block" href="/edwarddh101" data-ga-click="Header, go to profile, text:Signed in as">Signed in as <strong class="css-truncate-target">edwarddh101</strong></a></div>
    <div role="none" class="dropdown-divider"></div>

      <div class="pl-3 pr-3 f6 user-status-container js-user-status-context pb-1" data-url="/users/status?compact=1&amp;link_mentions=0&amp;truncate=1">
        
<div class="js-user-status-container
    user-status-compact rounded-1 px-2 py-1 mt-2
    border
  " data-team-hovercards-enabled>
  <details class="js-user-status-details details-reset details-overlay details-overlay-dark">
    <summary class="btn-link btn-block link-gray no-underline js-toggle-user-status-edit toggle-user-status-edit "
      role="menuitem" data-hydro-click="{&quot;event_type&quot;:&quot;user_profile.click&quot;,&quot;payload&quot;:{&quot;profile_user_id&quot;:5132781,&quot;target&quot;:&quot;EDIT_USER_STATUS&quot;,&quot;user_id&quot;:8853113,&quot;client_id&quot;:&quot;1814175083.1566936942&quot;,&quot;originating_request_id&quot;:&quot;6009:9A74:2DFC5:43931:5D659AA5&quot;,&quot;originating_url&quot;:&quot;https://github.com/GalvanizeDataScience/interview-prep/blob/master/review/Model_Comparison_Guide.md&quot;,&quot;referrer&quot;:&quot;https://github.com/GalvanizeDataScience/interview-prep/tree/master/review&quot;}}" data-hydro-click-hmac="afaf2cf6c5d3fd2c76dc848f66b31b501f43cc7e17595a32058febe6b42f554e">
      <div class="d-flex">
        <div class="f6 lh-condensed user-status-header
          d-inline-block v-align-middle
            user-status-emoji-only-header circle
            pr-2
"
            style="max-width: 29px"
          >
          <div class="user-status-emoji-container flex-shrink-0 mr-1 mt-1 lh-condensed-ultra v-align-bottom" style="">
            <svg class="octicon octicon-smiley" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 0C3.58 0 0 3.58 0 8s3.58 8 8 8 8-3.58 8-8-3.58-8-8-8zm4.81 12.81a6.72 6.72 0 0 1-2.17 1.45c-.83.36-1.72.53-2.64.53-.92 0-1.81-.17-2.64-.53-.81-.34-1.55-.83-2.17-1.45a6.773 6.773 0 0 1-1.45-2.17A6.59 6.59 0 0 1 1.21 8c0-.92.17-1.81.53-2.64.34-.81.83-1.55 1.45-2.17.62-.62 1.36-1.11 2.17-1.45A6.59 6.59 0 0 1 8 1.21c.92 0 1.81.17 2.64.53.81.34 1.55.83 2.17 1.45.62.62 1.11 1.36 1.45 2.17.36.83.53 1.72.53 2.64 0 .92-.17 1.81-.53 2.64-.34.81-.83 1.55-1.45 2.17zM4 6.8v-.59c0-.66.53-1.19 1.2-1.19h.59c.66 0 1.19.53 1.19 1.19v.59c0 .67-.53 1.2-1.19 1.2H5.2C4.53 8 4 7.47 4 6.8zm5 0v-.59c0-.66.53-1.19 1.2-1.19h.59c.66 0 1.19.53 1.19 1.19v.59c0 .67-.53 1.2-1.19 1.2h-.59C9.53 8 9 7.47 9 6.8zm4 3.2c-.72 1.88-2.91 3-5 3s-4.28-1.13-5-3c-.14-.39.23-1 .66-1h8.59c.41 0 .89.61.75 1z"/></svg>
          </div>
        </div>
        <div class="
          d-inline-block v-align-middle
          
          
           css-truncate css-truncate-target 
           user-status-message-wrapper f6"
           style="line-height: 20px;" >
          <div class="d-inline-block text-gray-dark v-align-text-top text-left">
              <span class="text-gray ml-2">Set status</span>
          </div>
        </div>
      </div>
    </summary>
    <details-dialog class="details-dialog rounded-1 anim-fade-in fast Box Box--overlay" role="dialog" tabindex="-1">
      <!-- '"` --><!-- </textarea></xmp> --></option></form><form class="position-relative flex-auto js-user-status-form" action="/users/status?compact=1&amp;link_mentions=0&amp;truncate=1" accept-charset="UTF-8" method="post"><input name="utf8" type="hidden" value="&#x2713;" /><input type="hidden" name="_method" value="put" /><input type="hidden" name="authenticity_token" value="gSoruXhXcKcpMCws8J/v3aP91Kth4ULMe6QpeCyfoXr0HJDf8TYmOoSIyfCMn/CpTOQcbIZmQ6Iv7FH7nllquw==" />
        <div class="Box-header bg-gray border-bottom p-3">
          <button class="Box-btn-octicon js-toggle-user-status-edit btn-octicon float-right" type="reset" aria-label="Close dialog" data-close-dialog>
            <svg class="octicon octicon-x" viewBox="0 0 12 16" version="1.1" width="12" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.48 8l3.75 3.75-1.48 1.48L6 9.48l-3.75 3.75-1.48-1.48L4.52 8 .77 4.25l1.48-1.48L6 6.52l3.75-3.75 1.48 1.48L7.48 8z"/></svg>
          </button>
          <h3 class="Box-title f5 text-bold text-gray-dark">Edit status</h3>
        </div>
        <input type="hidden" name="emoji" class="js-user-status-emoji-field" value="">
        <input type="hidden" name="organization_id" class="js-user-status-org-id-field" value="">
        <div class="px-3 py-2 text-gray-dark">
          <div class="js-characters-remaining-container position-relative mt-2">
            <div class="input-group d-table form-group my-0 js-user-status-form-group">
              <span class="input-group-button d-table-cell v-align-middle" style="width: 1%">
                <button type="button" aria-label="Choose an emoji" class="btn-outline btn js-toggle-user-status-emoji-picker btn-open-emoji-picker p-0">
                  <span class="js-user-status-original-emoji" hidden></span>
                  <span class="js-user-status-custom-emoji"></span>
                  <span class="js-user-status-no-emoji-icon" >
                    <svg class="octicon octicon-smiley" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 0C3.58 0 0 3.58 0 8s3.58 8 8 8 8-3.58 8-8-3.58-8-8-8zm4.81 12.81a6.72 6.72 0 0 1-2.17 1.45c-.83.36-1.72.53-2.64.53-.92 0-1.81-.17-2.64-.53-.81-.34-1.55-.83-2.17-1.45a6.773 6.773 0 0 1-1.45-2.17A6.59 6.59 0 0 1 1.21 8c0-.92.17-1.81.53-2.64.34-.81.83-1.55 1.45-2.17.62-.62 1.36-1.11 2.17-1.45A6.59 6.59 0 0 1 8 1.21c.92 0 1.81.17 2.64.53.81.34 1.55.83 2.17 1.45.62.62 1.11 1.36 1.45 2.17.36.83.53 1.72.53 2.64 0 .92-.17 1.81-.53 2.64-.34.81-.83 1.55-1.45 2.17zM4 6.8v-.59c0-.66.53-1.19 1.2-1.19h.59c.66 0 1.19.53 1.19 1.19v.59c0 .67-.53 1.2-1.19 1.2H5.2C4.53 8 4 7.47 4 6.8zm5 0v-.59c0-.66.53-1.19 1.2-1.19h.59c.66 0 1.19.53 1.19 1.19v.59c0 .67-.53 1.2-1.19 1.2h-.59C9.53 8 9 7.47 9 6.8zm4 3.2c-.72 1.88-2.91 3-5 3s-4.28-1.13-5-3c-.14-.39.23-1 .66-1h8.59c.41 0 .89.61.75 1z"/></svg>
                  </span>
                </button>
              </span>
              <text-expander keys=": @" data-mention-url="/autocomplete/user-suggestions" data-emoji-url="/autocomplete/emoji">
                <input
                  type="text"
                  autocomplete="off"
                  data-no-org-url="/autocomplete/user-suggestions"
                  data-org-url="/suggestions?mention_suggester=1"
                  data-maxlength="80"
                  class="d-table-cell width-full form-control js-user-status-message-field js-characters-remaining-field"
                  placeholder="What's happening?"
                  name="message"
                  value=""
                  aria-label="What is your current status?">
              </text-expander>
              <div class="error">Could not update your status, please try again.</div>
            </div>
            <div style="margin-left: 53px" class="my-1 text-small label-characters-remaining js-characters-remaining" data-suffix="remaining" hidden>
              80 remaining
            </div>
          </div>
          <include-fragment class="js-user-status-emoji-picker" data-url="/users/status/emoji"></include-fragment>
          <div class="overflow-auto ml-n3 mr-n3 px-3 border-bottom" style="max-height: 33vh">
            <div class="user-status-suggestions js-user-status-suggestions collapsed overflow-hidden">
              <h4 class="f6 text-normal my-3">Suggestions:</h4>
              <div class="mx-3 mt-2 clearfix">
                  <div class="float-left col-6">
                      <button type="button" value=":palm_tree:" class="d-flex flex-items-baseline flex-items-stretch lh-condensed f6 btn-link link-gray no-underline js-predefined-user-status mb-1">
                        <div class="emoji-status-width mr-2 v-align-middle js-predefined-user-status-emoji">
                          <g-emoji alias="palm_tree" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f334.png">üå¥</g-emoji>
                        </div>
                        <div class="d-flex flex-items-center no-underline js-predefined-user-status-message ws-normal text-left" style="border-left: 1px solid transparent">
                          On vacation
                        </div>
                      </button>
                      <button type="button" value=":face_with_thermometer:" class="d-flex flex-items-baseline flex-items-stretch lh-condensed f6 btn-link link-gray no-underline js-predefined-user-status mb-1">
                        <div class="emoji-status-width mr-2 v-align-middle js-predefined-user-status-emoji">
                          <g-emoji alias="face_with_thermometer" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f912.png">ü§í</g-emoji>
                        </div>
                        <div class="d-flex flex-items-center no-underline js-predefined-user-status-message ws-normal text-left" style="border-left: 1px solid transparent">
                          Out sick
                        </div>
                      </button>
                  </div>
                  <div class="float-left col-6">
                      <button type="button" value=":house:" class="d-flex flex-items-baseline flex-items-stretch lh-condensed f6 btn-link link-gray no-underline js-predefined-user-status mb-1">
                        <div class="emoji-status-width mr-2 v-align-middle js-predefined-user-status-emoji">
                          <g-emoji alias="house" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3e0.png">üè†</g-emoji>
                        </div>
                        <div class="d-flex flex-items-center no-underline js-predefined-user-status-message ws-normal text-left" style="border-left: 1px solid transparent">
                          Working from home
                        </div>
                      </button>
                      <button type="button" value=":dart:" class="d-flex flex-items-baseline flex-items-stretch lh-condensed f6 btn-link link-gray no-underline js-predefined-user-status mb-1">
                        <div class="emoji-status-width mr-2 v-align-middle js-predefined-user-status-emoji">
                          <g-emoji alias="dart" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png">üéØ</g-emoji>
                        </div>
                        <div class="d-flex flex-items-center no-underline js-predefined-user-status-message ws-normal text-left" style="border-left: 1px solid transparent">
                          Focusing
                        </div>
                      </button>
                  </div>
              </div>
            </div>
            <div class="user-status-limited-availability-container">
              <div class="form-checkbox my-0">
                <input type="checkbox" name="limited_availability" value="1" class="js-user-status-limited-availability-checkbox" data-default-message="I may be slow to respond." aria-describedby="limited-availability-help-text-truncate-true-compact-true" id="limited-availability-truncate-true-compact-true">
                <label class="d-block f5 text-gray-dark mb-1" for="limited-availability-truncate-true-compact-true">
                  Busy
                </label>
                <p class="note" id="limited-availability-help-text-truncate-true-compact-true">
                  When others mention you, assign you, or request your review,
                  GitHub will let them know that you have limited availability.
                </p>
              </div>
            </div>
          </div>
            

<div class="d-inline-block f5 mr-2 pt-3 pb-2" >
  <div class="d-inline-block mr-1">
    Clear status
  </div>

  <details class="js-user-status-expire-drop-down f6 dropdown details-reset details-overlay d-inline-block mr-2">
    <summary class="f5 btn-link link-gray-dark border px-2 py-1 rounded-1" aria-haspopup="true">
      <div class="js-user-status-expiration-interval-selected d-inline-block v-align-baseline">
        Never
      </div>
      <div class="dropdown-caret"></div>
    </summary>

    <ul class="dropdown-menu dropdown-menu-se pl-0 overflow-auto" style="width: 220px; max-height: 15.5em">
      <li>
        <button type="button" class="btn-link dropdown-item js-user-status-expire-button ws-normal" title="Never">
          <span class="d-inline-block text-bold mb-1">Never</span>
          <div class="f6 lh-condensed">Keep this status until you clear your status or edit your status.</div>
        </button>
      </li>
      <li class="dropdown-divider" role="none"></li>
        <li>
          <button type="button" class="btn-link dropdown-item ws-normal js-user-status-expire-button" title="in 30 minutes" value="2019-08-27T14:33:43-07:00">
            in 30 minutes
          </button>
        </li>
        <li>
          <button type="button" class="btn-link dropdown-item ws-normal js-user-status-expire-button" title="in 1 hour" value="2019-08-27T15:03:43-07:00">
            in 1 hour
          </button>
        </li>
        <li>
          <button type="button" class="btn-link dropdown-item ws-normal js-user-status-expire-button" title="in 4 hours" value="2019-08-27T18:03:43-07:00">
            in 4 hours
          </button>
        </li>
        <li>
          <button type="button" class="btn-link dropdown-item ws-normal js-user-status-expire-button" title="today" value="2019-08-27T23:59:59-07:00">
            today
          </button>
        </li>
        <li>
          <button type="button" class="btn-link dropdown-item ws-normal js-user-status-expire-button" title="this week" value="2019-09-01T23:59:59-07:00">
            this week
          </button>
        </li>
    </ul>
  </details>
  <input class="js-user-status-expiration-date-input" type="hidden" name="expires_at" value="">
</div>

          <include-fragment class="js-user-status-org-picker" data-url="/users/status/organizations"></include-fragment>
        </div>
        <div class="d-flex flex-items-center flex-justify-between p-3 border-top">
          <button type="submit" disabled class="width-full btn btn-primary mr-2 js-user-status-submit">
            Set status
          </button>
          <button type="button" disabled class="width-full js-clear-user-status-button btn ml-2 ">
            Clear status
          </button>
        </div>
</form>    </details-dialog>
  </details>
</div>

      </div>
      <div role="none" class="dropdown-divider"></div>


    <a role="menuitem" class="dropdown-item" href="/edwarddh101" data-ga-click="Header, go to profile, text:your profile">Your profile</a>



    <a role="menuitem" class="dropdown-item" href="/edwarddh101?tab=repositories" data-ga-click="Header, go to repositories, text:your repositories">Your repositories</a>

    <a role="menuitem" class="dropdown-item" href="/edwarddh101?tab=projects" data-ga-click="Header, go to projects, text:your projects">Your projects</a>

    <a role="menuitem" class="dropdown-item" href="/edwarddh101?tab=stars" data-ga-click="Header, go to starred repos, text:your stars">Your stars</a>
      <a role="menuitem" class="dropdown-item" href="https://gist.github.com/mine" data-ga-click="Header, your gists, text:your gists">Your gists</a>


    <div role="none" class="dropdown-divider"></div>
    <a role="menuitem" class="dropdown-item" href="https://help.github.com" data-ga-click="Header, go to help, text:help">Help</a>
    <a role="menuitem" class="dropdown-item" href="/settings/profile" data-ga-click="Header, go to settings, icon:settings">Settings</a>
    <!-- '"` --><!-- </textarea></xmp> --></option></form><form class="logout-form" action="/logout" accept-charset="UTF-8" method="post"><input name="utf8" type="hidden" value="&#x2713;" /><input type="hidden" name="authenticity_token" value="up8XdeLrs//hNfAM4exZLkxtvQNj1DHVdwmb7PTAF4quea/FJ81uUHJ0rQIR5ZjgnAwnvsvzgMX50pX5Qd8GMg==" />
      
      <button type="submit" class="dropdown-item dropdown-signout" data-ga-click="Header, sign out, icon:logout" role="menuitem">
        Sign out
      </button>
</form>  </details-menu>
</details>

    </div>

  </header>

      

  </div>

  <div id="start-of-content" class="show-on-focus"></div>


    <div id="js-flash-container">

</div>



  <div class="application-main " data-commit-hovercards-enabled>
        <div itemscope itemtype="http://schema.org/SoftwareSourceCode" class="">
    <main  >
      


  

      <div class="border-bottom shelf intro-shelf js-notice mb-0 pb-4">
  <div class="width-full container">
    <div class="width-full mx-auto shelf-content">
      <h2 class="shelf-title">Learn Git and GitHub without any code!</h2>
      <p class="shelf-lead">
          Using the Hello World guide, you‚Äôll start a branch, write comments, and open a pull request.
      </p>
      <a class="btn btn-primary shelf-cta" target="_blank" data-hydro-click="{&quot;event_type&quot;:&quot;repository.click&quot;,&quot;payload&quot;:{&quot;target&quot;:&quot;READ_GUIDE&quot;,&quot;repository_id&quot;:26934610,&quot;client_id&quot;:&quot;1814175083.1566936942&quot;,&quot;originating_request_id&quot;:&quot;6009:9A74:2DFC5:43931:5D659AA5&quot;,&quot;originating_url&quot;:&quot;https://github.com/GalvanizeDataScience/interview-prep/blob/master/review/Model_Comparison_Guide.md&quot;,&quot;referrer&quot;:&quot;https://github.com/GalvanizeDataScience/interview-prep/tree/master/review&quot;,&quot;user_id&quot;:8853113}}" data-hydro-click-hmac="af35eeed8fdbcbf0519a2b1262eff6784c38827174ebbe2c20edfc4952267939" href="https://guides.github.com/activities/hello-world/">Read the guide</a>
    </div>
    <!-- '"` --><!-- </textarea></xmp> --></option></form><form class="shelf-dismiss js-notice-dismiss" action="/dashboard/dismiss_bootcamp" accept-charset="UTF-8" method="post"><input name="utf8" type="hidden" value="&#x2713;" /><input type="hidden" name="_method" value="delete" /><input type="hidden" name="authenticity_token" value="Ec+uZrOMuEVbp0YXCpHcMiV1FrVLu6oF70NiL1eNyGE5KsMH/7aaGa7FGBvMFhT2NaxaVQLW2AOfm2kzHaJRsQ==" />
      <button name="button" type="submit" class="mr-1 close-button tooltipped tooltipped-w" aria-label="Hide this notice forever" data-hydro-click="{&quot;event_type&quot;:&quot;repository.click&quot;,&quot;payload&quot;:{&quot;target&quot;:&quot;DISMISS_BANNER&quot;,&quot;repository_id&quot;:26934610,&quot;client_id&quot;:&quot;1814175083.1566936942&quot;,&quot;originating_request_id&quot;:&quot;6009:9A74:2DFC5:43931:5D659AA5&quot;,&quot;originating_url&quot;:&quot;https://github.com/GalvanizeDataScience/interview-prep/blob/master/review/Model_Comparison_Guide.md&quot;,&quot;referrer&quot;:&quot;https://github.com/GalvanizeDataScience/interview-prep/tree/master/review&quot;,&quot;user_id&quot;:8853113}}" data-hydro-click-hmac="80d80011b2cf9942f81c0bd1af8965a24191b1d29fa334cc22ee837b69a9b45d">
        <svg aria-label="Hide this notice forever" class="octicon octicon-x v-align-text-top" viewBox="0 0 12 16" version="1.1" width="12" height="16" role="img"><path fill-rule="evenodd" d="M7.48 8l3.75 3.75-1.48 1.48L6 9.48l-3.75 3.75-1.48-1.48L4.52 8 .77 4.25l1.48-1.48L6 6.52l3.75-3.75 1.48 1.48L7.48 8z"/></svg>
</button></form>  </div>
</div>



  








  <div class="pagehead repohead instapaper_ignore readability-menu experiment-repo-nav pt-0 pt-lg-4 ">
    <div class="repohead-details-container clearfix container-lg p-responsive d-none d-lg-block">

      <ul class="pagehead-actions">




  <li>
    
    <!-- '"` --><!-- </textarea></xmp> --></option></form><form data-remote="true" class="clearfix js-social-form js-social-container" action="/notifications/subscribe" accept-charset="UTF-8" method="post"><input name="utf8" type="hidden" value="&#x2713;" /><input type="hidden" name="authenticity_token" value="Mg8WM37D7fDWKw8JJ+VSYLAyyPttYuVga/M6Kufn47n8BCdbpOr4ZzAgxKyGxGUkPOEUOzY5y02z8cabXcZIRg==" />      <input type="hidden" name="repository_id" value="26934610">

      <details class="details-reset details-overlay select-menu float-left">
        <summary class="select-menu-button float-left btn btn-sm btn-with-count" data-hydro-click="{&quot;event_type&quot;:&quot;repository.click&quot;,&quot;payload&quot;:{&quot;target&quot;:&quot;WATCH_BUTTON&quot;,&quot;repository_id&quot;:26934610,&quot;client_id&quot;:&quot;1814175083.1566936942&quot;,&quot;originating_request_id&quot;:&quot;6009:9A74:2DFC5:43931:5D659AA5&quot;,&quot;originating_url&quot;:&quot;https://github.com/GalvanizeDataScience/interview-prep/blob/master/review/Model_Comparison_Guide.md&quot;,&quot;referrer&quot;:&quot;https://github.com/GalvanizeDataScience/interview-prep/tree/master/review&quot;,&quot;user_id&quot;:8853113}}" data-hydro-click-hmac="90f53335205bb0932ea80326a4c0f012f76b2aa34275d882d4874d65e1a2a9ae" data-ga-click="Repository, click Watch settings, action:blob#show">          <span data-menu-button>
              <svg class="octicon octicon-eye v-align-text-bottom" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8.06 2C3 2 0 8 0 8s3 6 8.06 6C13 14 16 8 16 8s-3-6-7.94-6zM8 12c-2.2 0-4-1.78-4-4 0-2.2 1.8-4 4-4 2.22 0 4 1.8 4 4 0 2.22-1.78 4-4 4zm2-4c0 1.11-.89 2-2 2-1.11 0-2-.89-2-2 0-1.11.89-2 2-2 1.11 0 2 .89 2 2z"/></svg>
              Watch
          </span>
</summary>        <details-menu
          class="select-menu-modal position-absolute mt-5"
          style="z-index: 99;">
          <div class="select-menu-header">
            <span class="select-menu-title">Notifications</span>
          </div>
          <div class="select-menu-list">
            <button type="submit" name="do" value="included" class="select-menu-item width-full" aria-checked="true" role="menuitemradio">
              <svg class="octicon octicon-check select-menu-item-icon" viewBox="0 0 12 16" version="1.1" width="12" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M12 5l-8 8-4-4 1.5-1.5L4 10l6.5-6.5L12 5z"/></svg>
              <div class="select-menu-item-text">
                <span class="select-menu-item-heading">Not watching</span>
                <span class="description">Be notified only when participating or @mentioned.</span>
                <span class="hidden-select-button-text" data-menu-button-contents>
                  <svg class="octicon octicon-eye v-align-text-bottom" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8.06 2C3 2 0 8 0 8s3 6 8.06 6C13 14 16 8 16 8s-3-6-7.94-6zM8 12c-2.2 0-4-1.78-4-4 0-2.2 1.8-4 4-4 2.22 0 4 1.8 4 4 0 2.22-1.78 4-4 4zm2-4c0 1.11-.89 2-2 2-1.11 0-2-.89-2-2 0-1.11.89-2 2-2 1.11 0 2 .89 2 2z"/></svg>
                  Watch
                </span>
              </div>
            </button>

            <button type="submit" name="do" value="release_only" class="select-menu-item width-full" aria-checked="false" role="menuitemradio">
              <svg class="octicon octicon-check select-menu-item-icon" viewBox="0 0 12 16" version="1.1" width="12" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M12 5l-8 8-4-4 1.5-1.5L4 10l6.5-6.5L12 5z"/></svg>
              <div class="select-menu-item-text">
                <span class="select-menu-item-heading">Releases only</span>
                <span class="description">Be notified of new releases, and when participating or @mentioned.</span>
                <span class="hidden-select-button-text" data-menu-button-contents>
                  <svg class="octicon octicon-eye v-align-text-bottom" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8.06 2C3 2 0 8 0 8s3 6 8.06 6C13 14 16 8 16 8s-3-6-7.94-6zM8 12c-2.2 0-4-1.78-4-4 0-2.2 1.8-4 4-4 2.22 0 4 1.8 4 4 0 2.22-1.78 4-4 4zm2-4c0 1.11-.89 2-2 2-1.11 0-2-.89-2-2 0-1.11.89-2 2-2 1.11 0 2 .89 2 2z"/></svg>
                  Unwatch releases
                </span>
              </div>
            </button>

            <button type="submit" name="do" value="subscribed" class="select-menu-item width-full" aria-checked="false" role="menuitemradio">
              <svg class="octicon octicon-check select-menu-item-icon" viewBox="0 0 12 16" version="1.1" width="12" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M12 5l-8 8-4-4 1.5-1.5L4 10l6.5-6.5L12 5z"/></svg>
              <div class="select-menu-item-text">
                <span class="select-menu-item-heading">Watching</span>
                <span class="description">Be notified of all conversations.</span>
                <span class="hidden-select-button-text" data-menu-button-contents>
                  <svg class="octicon octicon-eye v-align-text-bottom" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8.06 2C3 2 0 8 0 8s3 6 8.06 6C13 14 16 8 16 8s-3-6-7.94-6zM8 12c-2.2 0-4-1.78-4-4 0-2.2 1.8-4 4-4 2.22 0 4 1.8 4 4 0 2.22-1.78 4-4 4zm2-4c0 1.11-.89 2-2 2-1.11 0-2-.89-2-2 0-1.11.89-2 2-2 1.11 0 2 .89 2 2z"/></svg>
                  Unwatch
                </span>
              </div>
            </button>

            <button type="submit" name="do" value="ignore" class="select-menu-item width-full" aria-checked="false" role="menuitemradio">
              <svg class="octicon octicon-check select-menu-item-icon" viewBox="0 0 12 16" version="1.1" width="12" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M12 5l-8 8-4-4 1.5-1.5L4 10l6.5-6.5L12 5z"/></svg>
              <div class="select-menu-item-text">
                <span class="select-menu-item-heading">Ignoring</span>
                <span class="description">Never be notified.</span>
                <span class="hidden-select-button-text" data-menu-button-contents>
                  <svg class="octicon octicon-mute v-align-text-bottom" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 2.81v10.38c0 .67-.81 1-1.28.53L3 10H1c-.55 0-1-.45-1-1V7c0-.55.45-1 1-1h2l3.72-3.72C7.19 1.81 8 2.14 8 2.81zm7.53 3.22l-1.06-1.06-1.97 1.97-1.97-1.97-1.06 1.06L11.44 8 9.47 9.97l1.06 1.06 1.97-1.97 1.97 1.97 1.06-1.06L13.56 8l1.97-1.97z"/></svg>
                  Stop ignoring
                </span>
              </div>
            </button>
          </div>
        </details-menu>
      </details>
        <a class="social-count js-social-count"
          href="/GalvanizeDataScience/interview-prep/watchers"
          aria-label="68 users are watching this repository">
          68
        </a>
</form>
  </li>

  <li>
      <div class="js-toggler-container js-social-container starring-container ">
    <!-- '"` --><!-- </textarea></xmp> --></option></form><form class="starred js-social-form" action="/GalvanizeDataScience/interview-prep/unstar" accept-charset="UTF-8" method="post"><input name="utf8" type="hidden" value="&#x2713;" /><input type="hidden" name="authenticity_token" value="mA2FZ0ZUAeFAj1wsl+Gvhuj7mgyoMGhEyoGHJz3V2reXFeUloZEdw2cgYe7hp5+xWcQtzNc3XUOU5lKNLksYnA==" />
      <input type="hidden" name="context" value="repository"></input>
      <button type="submit" class="btn btn-sm btn-with-count js-toggler-target" aria-label="Unstar this repository" title="Unstar GalvanizeDataScience/interview-prep" data-hydro-click="{&quot;event_type&quot;:&quot;repository.click&quot;,&quot;payload&quot;:{&quot;target&quot;:&quot;UNSTAR_BUTTON&quot;,&quot;repository_id&quot;:26934610,&quot;client_id&quot;:&quot;1814175083.1566936942&quot;,&quot;originating_request_id&quot;:&quot;6009:9A74:2DFC5:43931:5D659AA5&quot;,&quot;originating_url&quot;:&quot;https://github.com/GalvanizeDataScience/interview-prep/blob/master/review/Model_Comparison_Guide.md&quot;,&quot;referrer&quot;:&quot;https://github.com/GalvanizeDataScience/interview-prep/tree/master/review&quot;,&quot;user_id&quot;:8853113}}" data-hydro-click-hmac="af09e5f72ddf284bb5698a13a176dfdf5d7d0e07067127965022713ff03dd228" data-ga-click="Repository, click unstar button, action:blob#show; text:Unstar">        <svg class="octicon octicon-star v-align-text-bottom" viewBox="0 0 14 16" version="1.1" width="14" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M14 6l-4.9-.64L7 1 4.9 5.36 0 6l3.6 3.26L2.67 14 7 11.67 11.33 14l-.93-4.74L14 6z"/></svg>
        Unstar
</button>        <a class="social-count js-social-count" href="/GalvanizeDataScience/interview-prep/stargazers"
           aria-label="9 users starred this repository">
           9
        </a>
</form>
    <!-- '"` --><!-- </textarea></xmp> --></option></form><form class="unstarred js-social-form" action="/GalvanizeDataScience/interview-prep/star" accept-charset="UTF-8" method="post"><input name="utf8" type="hidden" value="&#x2713;" /><input type="hidden" name="authenticity_token" value="aC/LsjYlttX15GqoR060kPlHbRTRjWZeAgWuafen4d5/VdWNqfXVBdZmzrbZLVh7W+SOJxesmybk6k9jGAhIhw==" />
      <input type="hidden" name="context" value="repository"></input>
      <button type="submit" class="btn btn-sm btn-with-count js-toggler-target" aria-label="Unstar this repository" title="Star GalvanizeDataScience/interview-prep" data-hydro-click="{&quot;event_type&quot;:&quot;repository.click&quot;,&quot;payload&quot;:{&quot;target&quot;:&quot;STAR_BUTTON&quot;,&quot;repository_id&quot;:26934610,&quot;client_id&quot;:&quot;1814175083.1566936942&quot;,&quot;originating_request_id&quot;:&quot;6009:9A74:2DFC5:43931:5D659AA5&quot;,&quot;originating_url&quot;:&quot;https://github.com/GalvanizeDataScience/interview-prep/blob/master/review/Model_Comparison_Guide.md&quot;,&quot;referrer&quot;:&quot;https://github.com/GalvanizeDataScience/interview-prep/tree/master/review&quot;,&quot;user_id&quot;:8853113}}" data-hydro-click-hmac="89005828cc1cf4ef7e7e687f1fc2e4c57456298cb44af1a36f4fdfb1d749d8cb" data-ga-click="Repository, click star button, action:blob#show; text:Star">        <svg class="octicon octicon-star v-align-text-bottom" viewBox="0 0 14 16" version="1.1" width="14" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M14 6l-4.9-.64L7 1 4.9 5.36 0 6l3.6 3.26L2.67 14 7 11.67 11.33 14l-.93-4.74L14 6z"/></svg>
        Star
</button>        <a class="social-count js-social-count" href="/GalvanizeDataScience/interview-prep/stargazers"
           aria-label="9 users starred this repository">
          9
        </a>
</form>  </div>

  </li>

  <li>
          <details class="details-reset details-overlay details-overlay-dark d-inline-block float-left">
            <summary class="btn btn-sm btn-with-count" data-hydro-click="{&quot;event_type&quot;:&quot;repository.click&quot;,&quot;payload&quot;:{&quot;target&quot;:&quot;FORK_BUTTON&quot;,&quot;repository_id&quot;:26934610,&quot;client_id&quot;:&quot;1814175083.1566936942&quot;,&quot;originating_request_id&quot;:&quot;6009:9A74:2DFC5:43931:5D659AA5&quot;,&quot;originating_url&quot;:&quot;https://github.com/GalvanizeDataScience/interview-prep/blob/master/review/Model_Comparison_Guide.md&quot;,&quot;referrer&quot;:&quot;https://github.com/GalvanizeDataScience/interview-prep/tree/master/review&quot;,&quot;user_id&quot;:8853113}}" data-hydro-click-hmac="30a76f8832102c42aa6d5f1084ba8b6178aabe0041fdef85f316c90af5a9e5b9" data-ga-click="Repository, show fork modal, action:blob#show; text:Fork" title="Fork your own copy of GalvanizeDataScience/interview-prep to your account">              <svg class="octicon octicon-repo-forked v-align-text-bottom" viewBox="0 0 10 16" version="1.1" width="10" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1a1.993 1.993 0 0 0-1 3.72V6L5 8 3 6V4.72A1.993 1.993 0 0 0 2 1a1.993 1.993 0 0 0-1 3.72V6.5l3 3v1.78A1.993 1.993 0 0 0 5 15a1.993 1.993 0 0 0 1-3.72V9.5l3-3V4.72A1.993 1.993 0 0 0 8 1zM2 4.2C1.34 4.2.8 3.65.8 3c0-.65.55-1.2 1.2-1.2.65 0 1.2.55 1.2 1.2 0 .65-.55 1.2-1.2 1.2zm3 10c-.66 0-1.2-.55-1.2-1.2 0-.65.55-1.2 1.2-1.2.65 0 1.2.55 1.2 1.2 0 .65-.55 1.2-1.2 1.2zm3-10c-.66 0-1.2-.55-1.2-1.2 0-.65.55-1.2 1.2-1.2.65 0 1.2.55 1.2 1.2 0 .65-.55 1.2-1.2 1.2z"/></svg>
              Fork
</summary>            <details-dialog
              class="anim-fade-in fast Box Box--overlay d-flex flex-column"
              src="/GalvanizeDataScience/interview-prep/fork?fragment=1"
              preload>
              <div class="Box-header">
                <button class="Box-btn-octicon btn-octicon float-right" type="button" aria-label="Close dialog" data-close-dialog>
                  <svg class="octicon octicon-x" viewBox="0 0 12 16" version="1.1" width="12" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.48 8l3.75 3.75-1.48 1.48L6 9.48l-3.75 3.75-1.48-1.48L4.52 8 .77 4.25l1.48-1.48L6 6.52l3.75-3.75 1.48 1.48L7.48 8z"/></svg>
                </button>
                <h3 class="Box-title">Fork interview-prep</h3>
              </div>
              <div class="overflow-auto text-center">
                <include-fragment>
                  <div class="octocat-spinner my-3" aria-label="Loading..."></div>
                  <p class="f5 text-gray">If this dialog fails to load, you can visit <a href="/GalvanizeDataScience/interview-prep/fork">the fork page</a> directly.</p>
                </include-fragment>
              </div>
            </details-dialog>
          </details>

    <a href="/GalvanizeDataScience/interview-prep/network/members" class="social-count"
       aria-label="294 users forked this repository">
      294
    </a>
  </li>
</ul>

      <h1 class="private ">
    <svg class="octicon octicon-lock" viewBox="0 0 12 16" version="1.1" width="12" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 13H3v-1h1v1zm8-6v7c0 .55-.45 1-1 1H1c-.55 0-1-.45-1-1V7c0-.55.45-1 1-1h1V4c0-2.2 1.8-4 4-4s4 1.8 4 4v2h1c.55 0 1 .45 1 1zM3.8 6h4.41V4c0-1.22-.98-2.2-2.2-2.2-1.22 0-2.2.98-2.2 2.2v2H3.8zM11 7H2v7h9V7zM4 8H3v1h1V8zm0 2H3v1h1v-1z"/></svg>
  <span class="author" itemprop="author"><a class="url fn" rel="author" data-hovercard-type="organization" data-hovercard-url="/orgs/GalvanizeDataScience/hovercard" href="/GalvanizeDataScience">GalvanizeDataScience</a></span><!--
--><span class="path-divider">/</span><!--
--><strong itemprop="name"><a data-pjax="#js-repo-pjax-container" href="/GalvanizeDataScience/interview-prep">interview-prep</a></strong>
  <span class="Label Label--outline v-align-middle ">Private</span>

</h1>

    </div>
    
<nav class="hx_reponav reponav js-repo-nav js-sidenav-container-pjax container-lg p-responsive d-none d-lg-block"
     itemscope
     itemtype="http://schema.org/BreadcrumbList"
    aria-label="Repository"
     data-pjax="#js-repo-pjax-container">

  <span itemscope itemtype="http://schema.org/ListItem" itemprop="itemListElement">
    <a class="js-selected-navigation-item selected reponav-item" itemprop="url" data-hotkey="g c" aria-current="page" data-selected-links="repo_source repo_downloads repo_commits repo_releases repo_tags repo_branches repo_packages /GalvanizeDataScience/interview-prep" href="/GalvanizeDataScience/interview-prep">
      <svg class="octicon octicon-code" viewBox="0 0 14 16" version="1.1" width="14" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M9.5 3L8 4.5 11.5 8 8 11.5 9.5 13 14 8 9.5 3zm-5 0L0 8l4.5 5L6 11.5 2.5 8 6 4.5 4.5 3z"/></svg>
      <span itemprop="name">Code</span>
      <meta itemprop="position" content="1">
</a>  </span>

    <span itemscope itemtype="http://schema.org/ListItem" itemprop="itemListElement">
      <a itemprop="url" data-hotkey="g i" class="js-selected-navigation-item reponav-item" data-selected-links="repo_issues repo_labels repo_milestones /GalvanizeDataScience/interview-prep/issues" href="/GalvanizeDataScience/interview-prep/issues">
        <svg class="octicon octicon-issue-opened" viewBox="0 0 14 16" version="1.1" width="14" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"/></svg>
        <span itemprop="name">Issues</span>
        <span class="Counter">1</span>
        <meta itemprop="position" content="2">
</a>    </span>

  <span itemscope itemtype="http://schema.org/ListItem" itemprop="itemListElement">
    <a data-hotkey="g p" itemprop="url" class="js-selected-navigation-item reponav-item" data-selected-links="repo_pulls checks /GalvanizeDataScience/interview-prep/pulls" href="/GalvanizeDataScience/interview-prep/pulls">
      <svg class="octicon octicon-git-pull-request" viewBox="0 0 12 16" version="1.1" width="12" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M11 11.28V5c-.03-.78-.34-1.47-.94-2.06C9.46 2.35 8.78 2.03 8 2H7V0L4 3l3 3V4h1c.27.02.48.11.69.31.21.2.3.42.31.69v6.28A1.993 1.993 0 0 0 10 15a1.993 1.993 0 0 0 1-3.72zm-1 2.92c-.66 0-1.2-.55-1.2-1.2 0-.65.55-1.2 1.2-1.2.65 0 1.2.55 1.2 1.2 0 .65-.55 1.2-1.2 1.2zM4 3c0-1.11-.89-2-2-2a1.993 1.993 0 0 0-1 3.72v6.56A1.993 1.993 0 0 0 2 15a1.993 1.993 0 0 0 1-3.72V4.72c.59-.34 1-.98 1-1.72zm-.8 10c0 .66-.55 1.2-1.2 1.2-.65 0-1.2-.55-1.2-1.2 0-.65.55-1.2 1.2-1.2.65 0 1.2.55 1.2 1.2zM2 4.2C1.34 4.2.8 3.65.8 3c0-.65.55-1.2 1.2-1.2.65 0 1.2.55 1.2 1.2 0 .65-.55 1.2-1.2 1.2z"/></svg>
      <span itemprop="name">Pull requests</span>
      <span class="Counter">0</span>
      <meta itemprop="position" content="3">
</a>  </span>


    <a data-hotkey="g b" class="js-selected-navigation-item reponav-item" data-selected-links="repo_projects new_repo_project repo_project /GalvanizeDataScience/interview-prep/projects" href="/GalvanizeDataScience/interview-prep/projects">
      <svg class="octicon octicon-project" viewBox="0 0 15 16" version="1.1" width="15" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M10 12h3V2h-3v10zm-4-2h3V2H6v8zm-4 4h3V2H2v12zm-1 1h13V1H1v14zM14 0H1a1 1 0 0 0-1 1v14a1 1 0 0 0 1 1h13a1 1 0 0 0 1-1V1a1 1 0 0 0-1-1z"/></svg>
      Projects
      <span class="Counter" >0</span>
</a>

    <a class="js-selected-navigation-item reponav-item" data-hotkey="g w" data-selected-links="repo_wiki /GalvanizeDataScience/interview-prep/wiki" href="/GalvanizeDataScience/interview-prep/wiki">
      <svg class="octicon octicon-book" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M3 5h4v1H3V5zm0 3h4V7H3v1zm0 2h4V9H3v1zm11-5h-4v1h4V5zm0 2h-4v1h4V7zm0 2h-4v1h4V9zm2-6v9c0 .55-.45 1-1 1H9.5l-1 1-1-1H2c-.55 0-1-.45-1-1V3c0-.55.45-1 1-1h5.5l1 1 1-1H15c.55 0 1 .45 1 1zm-8 .5L7.5 3H2v9h6V3.5zm7-.5H9.5l-.5.5V12h6V3z"/></svg>
      Wiki
</a>
    <a data-skip-pjax="true" class="js-selected-navigation-item reponav-item" data-selected-links="security alerts policy /GalvanizeDataScience/interview-prep/security/advisories" href="/GalvanizeDataScience/interview-prep/security/advisories">
      <svg class="octicon octicon-shield" viewBox="0 0 14 16" version="1.1" width="14" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M0 2l7-2 7 2v6.02C14 12.69 8.69 16 7 16c-1.69 0-7-3.31-7-7.98V2zm1 .75L7 1l6 1.75v5.268C13 12.104 8.449 15 7 15c-1.449 0-6-2.896-6-6.982V2.75zm1 .75L7 2v12c-1.207 0-5-2.482-5-5.985V3.5z"/></svg>
      Security
</a>
    <a class="js-selected-navigation-item reponav-item" data-selected-links="repo_graphs repo_contributors dependency_graph pulse people /GalvanizeDataScience/interview-prep/pulse" href="/GalvanizeDataScience/interview-prep/pulse">
      <svg class="octicon octicon-graph" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M16 14v1H0V0h1v14h15zM5 13H3V8h2v5zm4 0H7V3h2v10zm4 0h-2V6h2v7z"/></svg>
      Insights
</a>

</nav>

  <div class="reponav-wrapper reponav-small d-lg-none">
  <nav class="reponav js-reponav text-center no-wrap"
       itemscope
       itemtype="http://schema.org/BreadcrumbList">

    <span itemscope itemtype="http://schema.org/ListItem" itemprop="itemListElement">
      <a class="js-selected-navigation-item selected reponav-item" itemprop="url" aria-current="page" data-selected-links="repo_source repo_downloads repo_commits repo_releases repo_tags repo_branches repo_packages /GalvanizeDataScience/interview-prep" href="/GalvanizeDataScience/interview-prep">
        <span itemprop="name">Code</span>
        <meta itemprop="position" content="1">
</a>    </span>

      <span itemscope itemtype="http://schema.org/ListItem" itemprop="itemListElement">
        <a itemprop="url" class="js-selected-navigation-item reponav-item" data-selected-links="repo_issues repo_labels repo_milestones /GalvanizeDataScience/interview-prep/issues" href="/GalvanizeDataScience/interview-prep/issues">
          <span itemprop="name">Issues</span>
          <span class="Counter">1</span>
          <meta itemprop="position" content="2">
</a>      </span>

    <span itemscope itemtype="http://schema.org/ListItem" itemprop="itemListElement">
      <a itemprop="url" class="js-selected-navigation-item reponav-item" data-selected-links="repo_pulls checks /GalvanizeDataScience/interview-prep/pulls" href="/GalvanizeDataScience/interview-prep/pulls">
        <span itemprop="name">Pull requests</span>
        <span class="Counter">0</span>
        <meta itemprop="position" content="3">
</a>    </span>

      <span itemscope itemtype="http://schema.org/ListItem" itemprop="itemListElement">
        <a itemprop="url" class="js-selected-navigation-item reponav-item" data-selected-links="repo_projects new_repo_project repo_project /GalvanizeDataScience/interview-prep/projects" href="/GalvanizeDataScience/interview-prep/projects">
          <span itemprop="name">Projects</span>
          <span class="Counter">0</span>
          <meta itemprop="position" content="4">
</a>      </span>

      <span itemscope itemtype="http://schema.org/ListItem" itemprop="itemListElement">
        <a itemprop="url" class="js-selected-navigation-item reponav-item" data-selected-links="repo_wiki /GalvanizeDataScience/interview-prep/wiki" href="/GalvanizeDataScience/interview-prep/wiki">
          <span itemprop="name">Wiki</span>
          <meta itemprop="position" content="5">
</a>      </span>

      <a itemprop="url" class="js-selected-navigation-item reponav-item" data-selected-links="security alerts policy /GalvanizeDataScience/interview-prep/security/advisories" href="/GalvanizeDataScience/interview-prep/security/advisories">
        <span itemprop="name">Security</span>
        <meta itemprop="position" content="6">
</a>
      <a class="js-selected-navigation-item reponav-item" data-selected-links="pulse /GalvanizeDataScience/interview-prep/pulse" href="/GalvanizeDataScience/interview-prep/pulse">
        Pulse
</a>

  </nav>
</div>


  </div>
<div class="container-lg clearfix new-discussion-timeline experiment-repo-nav  p-responsive">
  <div class="repository-content ">

    
    


  


    <a class="d-none js-permalink-shortcut" data-hotkey="y" href="/GalvanizeDataScience/interview-prep/blob/a1afab3fac0a20082bbfe6b04d01a297a9c16b2f/review/Model_Comparison_Guide.md">Permalink</a>

    <!-- blob contrib key: blob_contributors:v21:e99b9f3e9f586324903c9cd9b5f029ba -->
      

    <div class="d-flex flex-items-start flex-shrink-0 pb-3 flex-column flex-md-row">
      <span class="d-flex flex-justify-between width-full width-md-auto">
        
<details class="details-reset details-overlay select-menu branch-select-menu  hx_rsm" id="branch-select-menu">
  <summary class="btn btn-sm select-menu-button css-truncate"
           data-hotkey="w"
           title="Switch branches or tags">
    <i>Branch:</i>
    <span class="css-truncate-target" data-menu-button>master</span>
  </summary>

  <details-menu class="select-menu-modal hx_rsm-modal position-absolute" style="z-index: 99;" src="/GalvanizeDataScience/interview-prep/ref-list/master/review/Model_Comparison_Guide.md?source_action=show&amp;source_controller=blob" preload>
    <include-fragment class="select-menu-loading-overlay anim-pulse">
      <svg height="32" class="octicon octicon-octoface" viewBox="0 0 16 16" version="1.1" width="32" aria-hidden="true"><path fill-rule="evenodd" d="M14.7 5.34c.13-.32.55-1.59-.13-3.31 0 0-1.05-.33-3.44 1.3-1-.28-2.07-.32-3.13-.32s-2.13.04-3.13.32c-2.39-1.64-3.44-1.3-3.44-1.3-.68 1.72-.26 2.99-.13 3.31C.49 6.21 0 7.33 0 8.69 0 13.84 3.33 15 7.98 15S16 13.84 16 8.69c0-1.36-.49-2.48-1.3-3.35zM8 14.02c-3.3 0-5.98-.15-5.98-3.35 0-.76.38-1.48 1.02-2.07 1.07-.98 2.9-.46 4.96-.46 2.07 0 3.88-.52 4.96.46.65.59 1.02 1.3 1.02 2.07 0 3.19-2.68 3.35-5.98 3.35zM5.49 9.01c-.66 0-1.2.8-1.2 1.78s.54 1.79 1.2 1.79c.66 0 1.2-.8 1.2-1.79s-.54-1.78-1.2-1.78zm5.02 0c-.66 0-1.2.79-1.2 1.78s.54 1.79 1.2 1.79c.66 0 1.2-.8 1.2-1.79s-.53-1.78-1.2-1.78z"/></svg>
    </include-fragment>
  </details-menu>
</details>

        <div class="BtnGroup flex-shrink-0 d-md-none">
          <a href="/GalvanizeDataScience/interview-prep/find/master"
                class="js-pjax-capture-input btn btn-sm BtnGroup-item"
                data-pjax
                data-hotkey="t">
            Find file
          </a>
          <clipboard-copy value="review/Model_Comparison_Guide.md" class="btn btn-sm BtnGroup-item">
            Copy path
          </clipboard-copy>
        </div>
      </span>
      <h2 id="blob-path" class="breadcrumb flex-auto min-width-0 text-normal flex-md-self-center ml-md-2 mr-md-3 my-2 my-md-0">
        <span class="js-repo-root text-bold"><span class="js-path-segment"><a data-pjax="true" href="/GalvanizeDataScience/interview-prep"><span>interview-prep</span></a></span></span><span class="separator">/</span><span class="js-path-segment"><a data-pjax="true" href="/GalvanizeDataScience/interview-prep/tree/master/review"><span>review</span></a></span><span class="separator">/</span><strong class="final-path">Model_Comparison_Guide.md</strong>
      </h2>

      <div class="BtnGroup flex-shrink-0 d-none d-md-inline-block">
        <a href="/GalvanizeDataScience/interview-prep/find/master"
              class="js-pjax-capture-input btn btn-sm BtnGroup-item"
              data-pjax
              data-hotkey="t">
          Find file
        </a>
        <clipboard-copy value="review/Model_Comparison_Guide.md" class="btn btn-sm BtnGroup-item">
          Copy path
        </clipboard-copy>
      </div>
    </div>



    
  <div class="Box Box--condensed d-flex flex-column flex-shrink-0">
      <div class="Box-body d-flex flex-justify-between bg-blue-light flex-column flex-md-row flex-items-start flex-md-items-center">
        <span class="pr-md-4 f6">
          <img class="avatar" width="20" height="20" alt="" src="https://camo.githubusercontent.com/e0ff42f22baa0cd23a231bcb5f0d37c907f21e02/68747470733a2f2f322e67726176617461722e636f6d2f6176617461722f34613937323861333632363537626639393863313261633965346439623232623f643d68747470732533412532462532466769746875622e6769746875626173736574732e636f6d253246696d6167657325324667726176617461727325324667726176617461722d757365722d3432302e706e6726723d6726733d313430" data-canonical-src="https://2.gravatar.com/avatar/4a9728a362657bf998c12ac9e4d9b22b?d=https%3A%2F%2Fgithub.githubassets.com%2Fimages%2Fgravatars%2Fgravatar-user-420.png&amp;r=g&amp;s=140" />
          <span class="text-bold link-gray-dark lh-default v-align-middle">Moses Marsh</span>
            <span class="lh-default v-align-middle">
              <a data-pjax="true" title="tiny formatting typo" class="link-gray" href="/GalvanizeDataScience/interview-prep/commit/a1afab3fac0a20082bbfe6b04d01a297a9c16b2f">tiny formatting typo</a>
            </span>
        </span>
        <span class="d-inline-block flex-shrink-0 v-align-bottom f6 mt-2 mt-md-0">
          <a class="pr-2 text-mono link-gray" href="/GalvanizeDataScience/interview-prep/commit/a1afab3fac0a20082bbfe6b04d01a297a9c16b2f" data-pjax>a1afab3</a>
          <relative-time datetime="2017-02-14T22:20:48Z">Feb 14, 2017</relative-time>
        </span>
      </div>

    <div class="Box-body d-flex flex-items-center flex-auto f6 border-bottom-0 flex-wrap" >
      <details class="details-reset details-overlay details-overlay-dark lh-default text-gray-dark float-left mr-2" id="blob_contributors_box">
        <summary class="btn-link">
          <span><strong>1</strong> contributor</span>
        </summary>
        <details-dialog
          class="Box Box--overlay d-flex flex-column anim-fade-in fast"
          aria-label="Users who have contributed to this file"
          src="/GalvanizeDataScience/interview-prep/contributors/master/review/Model_Comparison_Guide.md/list" preload>
          <div class="Box-header">
            <button class="Box-btn-octicon btn-octicon float-right" type="button" aria-label="Close dialog" data-close-dialog>
              <svg class="octicon octicon-x" viewBox="0 0 12 16" version="1.1" width="12" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.48 8l3.75 3.75-1.48 1.48L6 9.48l-3.75 3.75-1.48-1.48L4.52 8 .77 4.25l1.48-1.48L6 6.52l3.75-3.75 1.48 1.48L7.48 8z"/></svg>
            </button>
            <h3 class="Box-title">
              Users who have contributed to this file
            </h3>
          </div>
          <include-fragment class="octocat-spinner my-3" aria-label="Loading..."></include-fragment>
        </details-dialog>
      </details>
    </div>
  </div>





    <div class="Box mt-3 position-relative">
      
<div class="Box-header py-2 d-flex flex-column flex-shrink-0 flex-md-row flex-md-items-center">

  <div class="text-mono f6 flex-auto pr-3 flex-order-2 flex-md-order-1 mt-2 mt-md-0">
      899 lines (610 sloc)
      <span class="file-info-divider"></span>
    64.5 KB
  </div>

  <div class="d-flex py-1 py-md-0 flex-auto flex-order-1 flex-md-order-2 flex-sm-grow-0 flex-justify-between">

    <div class="BtnGroup">
      <a id="raw-url" class="btn btn-sm BtnGroup-item" href="/GalvanizeDataScience/interview-prep/raw/master/review/Model_Comparison_Guide.md">Raw</a>
        <a class="btn btn-sm js-update-url-with-hash BtnGroup-item" data-hotkey="b" href="/GalvanizeDataScience/interview-prep/blame/master/review/Model_Comparison_Guide.md">Blame</a>
      <a rel="nofollow" class="btn btn-sm BtnGroup-item" href="/GalvanizeDataScience/interview-prep/commits/master/review/Model_Comparison_Guide.md">History</a>
    </div>


    <div>
            <a class="btn-octicon tooltipped tooltipped-nw"
               href="x-github-client://openRepo/https://github.com/GalvanizeDataScience/interview-prep?branch=master&amp;filepath=review%2FModel_Comparison_Guide.md"
               aria-label="Open this file in GitHub Desktop"
               data-ga-click="Repository, open with desktop, type:mac">
                <svg class="octicon octicon-device-desktop" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M15 2H1c-.55 0-1 .45-1 1v9c0 .55.45 1 1 1h5.34c-.25.61-.86 1.39-2.34 2h8c-1.48-.61-2.09-1.39-2.34-2H15c.55 0 1-.45 1-1V3c0-.55-.45-1-1-1zm0 9H1V3h14v8z"/></svg>
            </a>

            <!-- '"` --><!-- </textarea></xmp> --></option></form><form class="inline-form js-update-url-with-hash" action="/GalvanizeDataScience/interview-prep/edit/master/review/Model_Comparison_Guide.md" accept-charset="UTF-8" method="post"><input name="utf8" type="hidden" value="&#x2713;" /><input type="hidden" name="authenticity_token" value="HT5vodIvYjh7SbjphqL1Uu/Kc+iCyX3ESnCOC/o2s5Ia/6eRBsGtigOGRjfxxRWJy2Fo0Um+uIfd/EJQmr8baw==" />
              <button class="btn-octicon tooltipped tooltipped-nw" type="submit"
                aria-label="Edit the file in your fork of this project" data-hotkey="e" data-disable-with>
                <svg class="octicon octicon-pencil" viewBox="0 0 14 16" version="1.1" width="14" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M0 12v3h3l8-8-3-3-8 8zm3 2H1v-2h1v1h1v1zm10.3-9.3L12 6 9 3l1.3-1.3a.996.996 0 0 1 1.41 0l1.59 1.59c.39.39.39 1.02 0 1.41z"/></svg>
              </button>
</form>
          <!-- '"` --><!-- </textarea></xmp> --></option></form><form class="inline-form" action="/GalvanizeDataScience/interview-prep/delete/master/review/Model_Comparison_Guide.md" accept-charset="UTF-8" method="post"><input name="utf8" type="hidden" value="&#x2713;" /><input type="hidden" name="authenticity_token" value="iJusSuLWWAaP/Y/BeRcAhSGY9zFWwmAehPS+nvC/z3yCjCUxSPH9H/vlvkK0wbicwk1G04s86wOGRtZ0DfgKRA==" />
            <button class="btn-octicon btn-octicon-danger tooltipped tooltipped-nw" type="submit"
              aria-label="Delete the file in your fork of this project" data-disable-with>
              <svg class="octicon octicon-trashcan" viewBox="0 0 12 16" version="1.1" width="12" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M11 2H9c0-.55-.45-1-1-1H5c-.55 0-1 .45-1 1H2c-.55 0-1 .45-1 1v1c0 .55.45 1 1 1v9c0 .55.45 1 1 1h7c.55 0 1-.45 1-1V5c.55 0 1-.45 1-1V3c0-.55-.45-1-1-1zm-1 12H3V5h1v8h1V5h1v8h1V5h1v8h1V5h1v9zm1-10H2V3h9v1z"/></svg>
            </button>
</form>    </div>
  </div>
</div>




      
  <div id="readme" class="Box-body readme blob instapaper_body js-code-block-container">
    <article class="markdown-body entry-content p-3 p-md-6" itemprop="text"><h1><a id="user-content-model-comparison" class="anchor" aria-hidden="true" href="#model-comparison"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Model Comparison</h1>
<h2><a id="user-content-table-of-contents" class="anchor" aria-hidden="true" href="#table-of-contents"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Table of Contents</h2>
<ol>
<li>
<p><a href="#high-level"><strong>High Level</strong></a></p>
</li>
<li>
<p><a href="#why-we-model">Why we model?</a></p>
</li>
<li>
<p><a href="#scoring-a-model">Scoring a model</a></p>
</li>
<li>
<p><a href="#cross-validation">Cross Validation</a></p>
</li>
<li>
<p><a href="#characteristics-of-models">Characteristics of Models</a></p>
</li>
<li>
<p><a href="#regression"><strong>Regression</strong></a></p>
</li>
<li>
<p><a href="#linear-regression">Linear Regression</a></p>
</li>
<li>
<p><a href="#k-nearest-neighbors-regression">k-Nearest Neighbors Regression</a></p>
</li>
<li>
<p><a href="#decision-tree-regression">Decision Tree Regression</a></p>
</li>
<li>
<p><a href="#bagged-tree-regression">Bagged Tree Regression</a></p>
</li>
<li>
<p><a href="#random-forest-regression">Random Forest Regression</a></p>
</li>
<li>
<p><a href="#boosted-trees-regression">Boosted Trees Regression</a></p>
</li>
<li>
<p><a href="#classification"><strong>Classification</strong></a></p>
</li>
<li>
<p><a href="#logistic-regression">Logistic Regression</a></p>
</li>
<li>
<p><a href="#k-nearest-neighbors-classifier">k-Nearest Neighbors Classifier</a></p>
</li>
<li>
<p><a href="#decision-tree-classifier">Decision Tree Classifier</a></p>
</li>
<li>
<p><a href="#bagged-tree-classifier">Bagged Tree Classifier</a></p>
</li>
<li>
<p><a href="#random-forest-classifier">Random Forest Classifier</a></p>
</li>
<li>
<p><a href="#boosted-trees-classifier">Boosted Trees Classifier</a></p>
</li>
<li>
<p><a href="#svm">SVM</a></p>
</li>
<li>
<p><a href="#neural-networks">Neural Networks</a></p>
</li>
<li>
<p><a href="#naive-bayes">Naive Bayes</a></p>
</li>
<li>
<p><a href="#unsupervised-learning"><strong>Unsupervised Learning</strong></a></p>
</li>
<li>
<p><a href="#k-means-clustering">k-means Clustering</a></p>
</li>
<li>
<p><a href="#hierarchical-clustering">Hierarchical Clustering</a></p>
</li>
<li>
<p><a href="#other-good-resources"><strong>Other Good Resources</strong></a></p>
</li>
</ol>
<h2><a id="user-content-high-level" class="anchor" aria-hidden="true" href="#high-level"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>High Level</h2>
<p>Notes here are generally applicable and will provide a good framework for this guide.</p>
<h3><a id="user-content-what-is-a-model" class="anchor" aria-hidden="true" href="#what-is-a-model"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>What is a model?</h3>
<p>At its core, a model represents a relationship between variables. Our goal is to define that relationship as well as we can, having to make some simplifying assumptions along the way.</p>
<p><a target="_blank" rel="noopener noreferrer" href="/GalvanizeDataScience/interview-prep/blob/master/review/images/gpa_sat.jpg"><img src="/GalvanizeDataScience/interview-prep/raw/master/review/images/gpa_sat.jpg" alt="Linear_Model" style="max-width:100%;"></a></p>
<h3><a id="user-content-why-we-model" class="anchor" aria-hidden="true" href="#why-we-model"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Why we model?</h3>
<p>There are two motivations for building models, <strong>prediction</strong> and <strong>inference</strong>.</p>
<p><strong>Prediction</strong> - Given a set of features, what is the most likely dependent variable.  Used when getting the right answer is the goal.  Example - Predicting the stock market.</p>
<p><strong>Inference</strong> - What are the most important features in determining the dependent variable.  Used when trying to understand the relationship between the feature set and dependent variable.  Example - Understanding the lifestyle characteristics most important in predicting diabetes.</p>
<p>There may be a trade-off between the two.  On one extreme, linear regression is great for inference - the coefficients in a linear regression model are great at explaining.  On the other extreme, a Gaussian kernel SVM may be more accurate, but it loses a lot of interpretablity.</p>
<h3><a id="user-content-scoring-a-model" class="anchor" aria-hidden="true" href="#scoring-a-model"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Scoring a model</h3>
<p>Generally, there are two major steps when we train a model.  <strong>Building the model given a set of inputs</strong> and <strong>choosing between models</strong>.  The pool of metrics used when building the model and choosing the model are the same for each model type.  The key difference is that we use one metric score when <strong>building the model</strong> and any number when <strong>choosing a model</strong>.</p>
<p><strong>Building the Model</strong>
Each type of model has its own algorithm / equation when fitting <em>a fixed set of inputs (independent variables)</em>.  The result of this process is a model.  Therefore, the process for building the model needs a target metric in order to optimize the model it will output.  This target metric is referred to as the <em>loss</em> and training tries to minimize the <em>loss</em>.  The most common <em>loss</em> metric when training a <em>linear regression</em> model is <strong>Residual Sum of Squares (RSS)</strong>, though it can be others.</p>
<p><strong>Choosing the Model</strong>
A given model is only as good as the data on which it was trained.  We often want to build multiple models using different model types and / or inputs and then compare them.  Unlike when building a model, when choosing a model, we (humans) are using our judgment to choose the best model.  Because models often provide a number of trade-offs, it's important to use a number of scoring metrics when determining the "best" model.</p>
<h4><a id="user-content-cross-validation" class="anchor" aria-hidden="true" href="#cross-validation"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Cross Validation</h4>
<p>When building a (supervised) model, we almost always want to build the model on a <strong>training set</strong> of data and validate its accuracy on the <strong>test set</strong>.  This will help us ensure we are choosing models that are <strong>robust</strong>--they score well for all types of possible data inputs.</p>
<p><strong>k-Fold CV</strong> is a type of cross validation (<a href="https://en.wikipedia.org/wiki/Cross-validation_(statistics)#Common_types_of_cross-validation" rel="nofollow">there are more</a>) which splits the data into k groups. For each of the k groups, it fits your model on all of the training data that is NOT in the kth group, uses this model to predict the target for observations in group k, and returns a score.  The scores for all k models are averaged and this average is used when determining if this is a good <em>model form</em> to choose.  If so, then a final model should be built on all training data and assessed against the original test data (often referred to as <em>holdout data</em>)</p>
<p><a target="_blank" rel="noopener noreferrer" href="/GalvanizeDataScience/interview-prep/blob/master/review/images/kfold.png"><img src="/GalvanizeDataScience/interview-prep/raw/master/review/images/kfold.png" alt="kfold CV" style="max-width:100%;"></a></p>
<h4><a id="user-content-characteristics-of-models" class="anchor" aria-hidden="true" href="#characteristics-of-models"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Characteristics of Models:</h4>
<ul>
<li>High dimensionality - How well does the model perform when the data has a lot of explanatory variables?  Assume there are more predictors (p) than points of data (n).</li>
<li>Training speed - How long does it take to train the model?</li>
<li>Prediction speed - Once a model is trained, how long will it take to make a prediction?</li>
<li>Interpretability - Can we determine the most important features and their direct cause in the model?  See inference above.</li>
<li>Communication - What's the 2-sentence overview for non-technical colleagues?</li>
<li>Visualization - How do we present the model / process visually?</li>
<li>Evaluation - What metrics are at hand to score the model in order to <strong>choose the best model</strong>.</li>
<li>Nonlinearity - How does this model react to nonlinear data?</li>
<li>n &lt;&lt; p - How does this model react when there are more predictors than data points?</li>
<li>Outliers - How robust is the model to outliers?</li>
<li>Overfitting - Does this model tend to overfit?</li>
<li>Hyperparameters - What levers can we tune in the model to help achieve a better score?</li>
<li>Online - Can the model be easily updated with new data (without fitting using previously fitted data)?</li>
<li>Unique attributes</li>
<li>Special use cases</li>
</ul>
<h4><a id="user-content-other-high-level-notes" class="anchor" aria-hidden="true" href="#other-high-level-notes"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Other High Level Notes</h4>
<p>More data usually beat a better model. Better features usually beat a better model. So data collection and feature engineering
typically trump model selection. Keep that in mind whenever you're tackling a new problem.</p>
<p>The data are usually messy: the inputs tend to be mixtures of quantitative, binary, and categorical variables, the latter often with many levels. There are generally many missing values, complete observations being rare. Distributions of numeric predictor and response variables are often long-tailed and highly skewed.</p>
<p>Usually only a small fraction of the large number of predictor variables that have been included in the analysis are actually relevant to prediction.</p>
<p>Furthermore, when doing model selection, trying out several models is one of the best ways to determine which model to use. And you may ultimately find that an ensemble works the best.</p>
<p>Things like speed, simplicity, and interpretability will often guide your choice of model on the job.</p>
<h2><a id="user-content-regression" class="anchor" aria-hidden="true" href="#regression"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Regression</h2>
<h4><a id="user-content-linear-regression" class="anchor" aria-hidden="true" href="#linear-regression"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Linear Regression</h4>
<p>Predict the values of the dependent variable on a <em>continuous</em> scale.  Makes the assumption that there is a <em>linear</em> relationship between the independent and dependent variables.  The most common form is <em>ordinary least squares (OLS)</em> which minimizes the <em>residual sum of squares</em> when fitting the model.</p>
<p><a target="_blank" rel="noopener noreferrer" href="/GalvanizeDataScience/interview-prep/blob/master/review/images/mult_lr_form.png"><img src="/GalvanizeDataScience/interview-prep/raw/master/review/images/mult_lr_form.png" alt="Linear Regression Formula" style="max-width:100%;"></a></p>
<ul>
<li>
<p>High dimensionality</p>
<ul>
<li>Linear regression can be performed with a number of independent variables, however, having too many will cause the model to be overfit.</li>
</ul>
</li>
<li>
<p>Training speed</p>
<ul>
<li>Depends on the size of the data, but generally a fast model to train.  <a href="http://scikit-learn.org/stable/modules/sgd.html#regression" rel="nofollow">Stochastic gradient descent</a> can be used to speed up training when training on more than 10,000 points</li>
</ul>
</li>
<li>
<p>Prediction speed</p>
<ul>
<li>Predictions are very fast as they are merely the dot product of the coefficient vector and the input matrix.</li>
</ul>
</li>
<li>
<p>Interpretability</p>
<ul>
<li>One of the biggest attractions of linear regression is the high degree of interpretability.  The coefficients of the linear regression model indicate the relationship between the predictor and the predicted value.  The coefficient of any single predictor can be interpreted as the change in the predicted value with a 1 unit increase in the predictor value <em>holding all other variables constant</em> (ISL, 63).</li>
</ul>
</li>
<li>
<p>Communication</p>
<ul>
<li>Linear regression models are introduced in many introductory courses and given the straight forward interpretation of the coefficients, are fairly easy to communicate.</li>
</ul>
</li>
<li>
<p>Visualization</p>
<ul>
<li>Visualizing is easy when there is a single predictor (and feasible if there are 2 predictors).  We can calculate the predicted values across the range of possible inputs and see the predictions directly as well as the magnitude of the changes.  Using 2 predictors will require a 3-D visualization.  Any more than 2-predictors is not visually feasible, so it is often best to determine the most important predictors and visualize the relationships with those.</li>
</ul>
<p><a target="_blank" rel="noopener noreferrer" href="/GalvanizeDataScience/interview-prep/blob/master/review/images/mult_lr.png"><img src="/GalvanizeDataScience/interview-prep/raw/master/review/images/mult_lr.png" alt="Multiple Linear Regression" style="max-width:100%;"></a></p>
</li>
<li>
<p>Evaluation</p>
<ul>
<li>
<p>When training the model, OLS uses <strong>RSS</strong> for the loss function (ISL, 62).  This ensures that we do not over or under estimate the model (since residuals are squared, they lose their sign) and that outliers are penalized (squaring the residual causes exponentially greater loss in large residuals).  Because of the squared term, it is not robust to outliers.</p>
<ul>
<li>If the data is expected to be particularly prone to outliers, <a href="https://en.wikipedia.org/wiki/Least_absolute_deviations" rel="nofollow">Least Absolute Residual (LAR)</a> can be used as the loss function.  This will weigh each residual equally and minimize the sum of the absolute values of each residual.  However, LAR models are not robust, so if the training data is not representative of the actual data or if the data is inherently highly variable, the model will perform poorly.</li>
</ul>
</li>
<li>
<p>When deciding between models, the most common metric to use is <strong>R^2</strong>.   R^2 is described as <em>the proportion of variability in Y that can be explained by X</em>.  This is better understood when one considers how we calculate R^2.  R^2 = (TSS - RSS) / TSS, where TSS is the <em>total sum of squares</em> and is calculated as the sum of the residuals if we used the average value of Y as our predictor--i.e. how much do the data differ from the average value.  The RSS is the variability in the data that persists after we have created our best predictions.  So if we subtract out the variability that still persists from the total, we are left with the amount of variance that we have explained.  To normalize this value, we divide by the TSS.  Because R^2 is a normalized metric, it is not prone to the units of measurements in Y and will always between 0 and 1.  A "good" R^2 is dependent on the field of study.  Hard sciences typically have high values of R^2 while business regressions may consider an R^2 between 0.10 and 0.20 to be very good (ISL, 70).</p>
</li>
</ul>
<p><a target="_blank" rel="noopener noreferrer" href="/GalvanizeDataScience/interview-prep/blob/master/review/images/r2.png"><img src="/GalvanizeDataScience/interview-prep/raw/master/review/images/r2.png" alt="R^2" style="max-width:100%;"></a></p>
<ul>
<li>R^2 <strong>should not be used</strong> to compare models with different numbers of predictors.  More predictors <strong>will always</strong> increase R^2.  Rather, we should use <strong>Adjusted R^2</strong>, which penalizes models for each included predictor.  In addition to <strong>Adjusted R^2</strong>, we can also compare different models' <strong>AIC</strong>, <strong>BIC</strong>, and <strong>F-Statistic</strong>.</li>
</ul>
</li>
<li>
<p><a name="user-content-lr_nl_power">Nonlinearity</a></p>
<ul>
<li>When there isn't a strict linear relationship between the X and Y variables, we can transform the X variables by their square, cube, etc.  The model is still considered linear because there is a <strong>linear relationship between the coefficient and the input</strong>, despite that input being transformed.</li>
</ul>
</li>
<li>
<p><a name="user-content-lr_big_n_small_p">n &lt;&lt; p</a></p>
<ul>
<li>In addition to the problems of overfitting discussed above in high dimensional data, OLS will in fact not converge when there are more predictors than data points.  There is no unique least squares coefficient and the variance is infinite!  OLS cannot be used and we must decrease the number of predictors in the model (ISL, 204).</li>
</ul>
</li>
<li>
<p>Outliers</p>
<ul>
<li>
<p>Linear regressions is vulnerable to outliers (even when using an LAR score).  It is best to inspect the data before and after fitting a model to determine outliers.</p>
</li>
<li>
<p><a name="user-content-lr_outlier"></a>An easy way to detect outliers before fitting a model (for numerical values) is to use the 1.5 X IQR threshold.</p>
</li>
<li>
<p>After fitting the model, you can also look for points that are <strong>influential</strong> and / or have <strong>high leverage</strong>.</p>
<ul>
<li>
<p>Influential points are points whose inclusion will significantly change the slope of the model.</p>
<ul>
<li>Points with large residuals AND high leverage are more influential</li>
</ul>
</li>
<li>
<p>Leverage refers to points with unusual values in the X direction.</p>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><a name="user-content-lr_overfitting"></a>Overfitting</p>
<ul>
<li>
<p>Overfitting can be prevented by decreasing the number of predictors</p>
</li>
<li>
<p>Overfitting can also be prevented by ensuring we are cross-validating the model</p>
</li>
</ul>
</li>
<li>
<p>Hyperparameters</p>
<ul>
<li>OLS does not have any hyper-parameters, however, its cousins Lasso and Ridge regressions do.  See below.</li>
</ul>
</li>
<li>
<p>Online</p>
<ul>
<li>Can be updated online through <a href="https://en.wikipedia.org/wiki/Online_machine_learning#Stochastic_Gradient_Descent" rel="nofollow">stochastic gradient descent</a>.</li>
</ul>
</li>
<li>
<p>Unique attributes</p>
<ul>
<li>Assumes linear relationship between the independent and dependent variables</li>
<li>Assumes the error terms of all observations are normally distributed around a mean of 0</li>
<li>Assumes constant variance in observations</li>
<li>Scale the data if you want the coefficients to give you some indication of
feature importance. However, they will lose their interpretability.</li>
</ul>
</li>
<li>
<p><a name="user-content-lr_subset"></a>Special use cases<br>
There are 3 main techniques to prevent overfitting (ISL, 204):</p>
<pre><code>1. Subset Selection  
    Choose a subset of the predictors when creating the model.
    _Forward Stepwise_, _Backward Stepwise_, _Forward/Backward Stepwise_
2. Regularization (aka Shrinkage)
  Methods that _regularize_ (__shrink__) the coefficient estimates towards zero.  Shrinkage methods can significantly reduce variance.  __Ridge__ and __Lasso__ regressions are techniques for regularizing linear regression models.  Both penalize larger coefficients with a tuning parameter (lambda).  The greater the lambda value, the more regular the coefficients.  As lambda approaches infinity the coefficient estimates approach 0.  As lambda approaches 0, the coefficient estimates approach the estimates in a non-regularized linear regression model.

  __Ridge Regression__ uses an l2 scoring model, which squares the coefficients before summing.  __Lasso Regression__ uses an l1 scoring model, which sums the absolute values of the coefficients.  Lasso models have the added feature of letting feature coefficients equal 0, thus performing feature selection.  Ridge regularization models will include a non-zero value for each coefficient.  Neither method has proven to be universally better.

  The tuning parameter lambda should be chosen using cross-validation.

  ![Ridge Regularization](images/ridge.png) ![Lasso Regularization](images/lasso.png)  

3. Dimensionality Reduction  
  Use PCA or SVD to reduce the feature space.
</code></pre>
</li>
</ul>
<h4><a id="user-content-k-nearest-neighbors-regression" class="anchor" aria-hidden="true" href="#k-nearest-neighbors-regression"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>k-Nearest Neighbors Regression</h4>
<p>A model for predicting values by using the mean of the k "nearest" values.  "Nearness" is calculated with some distance metric between the value we are predicting for and all data points in the original data set.  <strong>Cosine Similarity</strong> and <strong>Euclidean Distance</strong> are the two most common similarity scores.  <strong>Cosine Similarity</strong> measures how different items are, but doesn't account for the magnitude of the difference.  <strong>Euclidean Distance</strong> penalizes differences with large magnitudes.</p>
<ul>
<li>
<p><a name="user-content-knn_reg_high_dim"></a>High dimensionality</p>
<ul>
<li>Suffers in high dimensions due to the <em>curse of dimensionality</em>.  While two points may be the "nearest", with a lot of dimensions, it's difficult to assess if they are actually similar, and thus a good proxy for value (ISL, 108).</li>
</ul>
</li>
<li>
<p><a name="user-content-knn_reg_ts"></a>Training speed</p>
<ul>
<li>KNN never trains a model, only predicts.</li>
</ul>
</li>
<li>
<p><a name="user-content-knn_reg_ps"></a>Prediction speed</p>
<ul>
<li>Prediction speed can be <a href="http://www.inf.ed.ac.uk/teaching/courses/iaml/slides/knn-2x2.pdf" rel="nofollow">slow</a> and grows with size of data set.</li>
</ul>
</li>
<li>
<p><a name="user-content-knn_reg_inter"></a>Interpretability</p>
<ul>
<li>It is <a href="https://www.quora.com/Classification-machine-learning/When-should-I-use-a-K-NN-classifier-over-a-Naive-Bayes-classifier" rel="nofollow">hard to determine the effect of any one feature in determining the overall prediction score</a>, so we cannot easily interpret the effects of the features.</li>
</ul>
</li>
<li>
<p><a name="user-content-knn_reg_com"></a>Communication</p>
<ul>
<li>The idea around KNN is fairly intuitive--use known data points that are similar to our unknown point to estimate the unknown point's target.  The distance concept may be a little foreign, but the Euclidean distance is a p-dimension extension of the Pythagorean theorem, so should be relatable to most.</li>
</ul>
</li>
<li>
<p><a name="user-content-knn_reg_viz"></a>Visualization</p>
<ul>
<li>Plotting two or three of the features for the data points against each other and then showing where the predicted point lies is a good way of visualizing the nearest neighbor concept.  You can expand this to the entire potential universe of values.</li>
</ul>
<p><a target="_blank" rel="noopener noreferrer" href="/GalvanizeDataScience/interview-prep/blob/master/review/images/knn.png"><img src="/GalvanizeDataScience/interview-prep/raw/master/review/images/knn.png" alt="KNN" style="max-width:100%;"></a></p>
</li>
<li>
<p><a name="user-content-knn_reg_eval"></a>Evaluation</p>
<ul>
<li>We can evaluate how appropriate KNN is as a regression model for a given data set by calculating the MSE and comparing it to the MSE from another regression model type (ISL, 106).</li>
</ul>
</li>
<li>
<p><a name="user-content-knn_reg_nl_p"></a>Nonlinearity</p>
<ul>
<li>KNN performs particularly well in nonlinear situations and will outperform linear regression models when the underlying data does not exhibit a linear relationship (ISL, 106).</li>
</ul>
</li>
<li>
<p><a name="user-content-knn_reg_big_n_small_p"></a>n &lt;&lt; p</p>
<ul>
<li>KNN suffers from the curse of dimensionality when p becomes too large.  n&lt;&lt;p is therefore especially troublesome (ISL, 108).</li>
</ul>
</li>
<li>
<p><a name="user-content-knn_reg_outlier"></a>Outliers</p>
<ul>
<li>KNN is prone to <a href="http://www.inf.ed.ac.uk/teaching/courses/iaml/slides/knn-2x2.pdf" rel="nofollow">outliers</a> because we take a simple average of the nearest neighbors.  If an outlier exists "close" to our predicted feature, that outlier's value will skew our prediction.</li>
</ul>
</li>
<li>
<p><a name="user-content-knn_reg_overfi"></a>Overfitting</p>
<ul>
<li>As the number of neighbors, k, approaches 1, KNN will be more likely to overfit.  To find the optimal k, create a holdout set from the observed data set and perform cross-validation by comparing different values of k and the resulting MSE when predicting on the holdout set.  The optimal value of k is the value that results in the largest decline in MSE ('elbow method') or minimizes MSE (ISL, 42).</li>
</ul>
</li>
<li>
<p><a name="user-content-knn_reg_hyperp"></a>Hyperparameters</p>
<ul>
<li>The number of nearest neighbors to choose, k.  k can be optimized through cross-validation (see Overfitting).</li>
</ul>
</li>
<li>
<p><a name="user-content-knn_reg_online"></a>Online</p>
<ul>
<li>Because there is no fitting involved, KNN can be performed online, so long as new data is added to the data set used for predictions.</li>
</ul>
</li>
<li>
<p><a name="user-content-knn_reg_unqatt"></a>Unique attributes</p>
<ul>
<li>Make sure to scale your data so that the distance calculation makes sense.</li>
<li>Noisy features will reduce performance, just as they would with k-means, since typically each feature is an equally-weighted dimension in the distance calculation.</li>
<li>Can incorporate mixtures of numeric and categorical predictor variables and missing values</li>
</ul>
</li>
<li>
<p><a name="user-content-knn_reg_spec_use_case"></a>Special use cases</p>
<ul>
<li>Can be used to fill in missing data by finding k nearest neighbors based on present features and then filling in the missing value based on the average of the nearest neighbors.</li>
</ul>
</li>
</ul>
<h4><a id="user-content-decision-tree-regression" class="anchor" aria-hidden="true" href="#decision-tree-regression"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Decision Tree Regression</h4>
<p>Decision trees are the basis for all <a href="https://en.wikipedia.org/wiki/Decision_tree_learning" rel="nofollow">decision tree learning</a> models.  These models are relatively intuitive and deal well with lots of features, outliers, and mixed data types.  Decision tree learning models are the closest thing to "off the shelf" models that can be implemented with relatively minimal engineering.</p>
<p>Regression trees iterate through the feature space, perform binary splits on the data to create two groups that are all the same on that given feature (if the feature is continuous, the split will be all values greater than and all values less than a certain threshold).  They then calculate the change in RSS from splitting on that feature.  After all features have been iterated through, the feature that resulted in the largest decrease in RSS will be used to split the data.  The same procedure is then performed on each split until RSS can no longer be decreased or some stopping criteria is hit (most likely in regression).  When the terminal split is not pure, the predicted value is the average of the values in the leaf.  Regression tress are <strong>greedy</strong> because they always split on the feature that will most decrease RSS <em>at that moment</em> rather than the split that is optimal in the end.  They are <strong>top down</strong> because they start at the top of the tree (no splits), and are <strong>recursive</strong> because they perform the same splitting process on each resulting split (ISL, 306).</p>
<p><a target="_blank" rel="noopener noreferrer" href="/GalvanizeDataScience/interview-prep/blob/master/review/images/golftree.gif"><img src="/GalvanizeDataScience/interview-prep/raw/master/review/images/golftree.gif" alt="Decision Tree" style="max-width:100%;"></a></p>
<ul>
<li>
<p><a name="user-content-dt_reg_high_dim"></a>High dimensionality</p>
<ul>
<li>When imposed with stopping criteria, regression trees work very well with high dimensional data.  A great characteristic of decision tree learning models is that they will perform feature selection--if a feature does not decrease RSS, then it will not be included in the final model.  Without stopping criteria, regression trees in high dimensional data will almost necessarily overfit (ISL, 307).</li>
</ul>
</li>
<li>
<p><a name="user-content-dt_reg_ts"></a>Training speed</p>
<ul>
<li>Decision trees are relatively slow to train, especially as the number of features increases.  This is fairly intuitive because at each split, the fitting algorithm iterates through each feature.  As the number of features grows, so does the length of iterations, as well as number of possible splits.</li>
</ul>
</li>
<li>
<p><a name="user-content-dt_reg_ps"></a>Prediction speed</p>
<ul>
<li>Fairly quick to predict.</li>
</ul>
</li>
<li>
<p><a name="user-content-dt_reg_inter"></a><a href="http://www.salford-systems.com/blog/dan-steinberg/what-is-the-variable-importance-measure" rel="nofollow">Interpretability</a></p>
<ul>
<li>Because each feature is considered at each split, there is not a straightforward interpretation of the effect changing a given predictor's value will have on the prediction value.  However, we can create rankings of the feature importance.  For each feature, we sum the resulting change in RSS at the nodes which use that feature for splitting.  At the end, we will have each feature and the cumulative decrease in RSS associated with that feature.  The features with the largest cumulative increase are the "most important" in this regression.</li>
</ul>
</li>
<li>
<p><a name="user-content-dt_reg_com"></a>Communication</p>
<ul>
<li>Decision trees closely mirror human decision making process and communicating the model should be fairly straightforward. (ISL, 315)  <em>For every possible feature on which we can segment our data, which will result in the largest gain?</em></li>
</ul>
</li>
<li>
<p><a name="user-content-dt_reg_viz"></a>Visualization</p>
<ul>
<li>Decision tree graphs are ubiquitous and great for visualizing the model (ISL, 315).</li>
</ul>
</li>
<li>
<p><a name="user-content-dt_reg_eval"></a>Evaluation</p>
<ul>
<li>
<p>By default, regression trees use RSS as the loss function, but there is no reason why another loss function cannot be used.  However, because regression trees are fairly robust to outliers, changing from RSS to LAR isn't as common as with linear regression (ISL, 306).</p>
</li>
<li>
<p>When <strong>choosing between models</strong>, RSS and <a href="https://www.quora.com/Does-a-low-R-square-make-my-decision-tree-model-unreliable" rel="nofollow">MSE</a> are both valid metrics.  There is less consensus on R^2 <a href="http://www.analyticbridge.com/forum/topics/rsquared-for-decision-tree" rel="nofollow">see reply by John Gins</a></p>
</li>
</ul>
</li>
<li>
<p><a name="user-content-dt_reg_nl_p"></a>Nonlinearity</p>
<ul>
<li>Decision tree learning models are particularly strong at fitting nonlinear data (ISL, 106).</li>
</ul>
</li>
<li>
<p><a name="user-content-dt_reg_big_n_small_p"></a>n &lt;&lt; p</p>
<ul>
<li>When n &lt;&lt; p, stopping criteria should be used in order to avoid overfitting.  Also consider using dimensionality reduction to ensure the features are <a href="http://scikit-learn.org/stable/modules/tree.html#tips-on-practical-use" rel="nofollow">discriminative</a>.</li>
</ul>
</li>
<li>
<p><a name="user-content-dt_reg_outlier"></a>Outliers</p>
<ul>
<li>Quite robust to outliers.</li>
</ul>
</li>
<li>
<p><a name="user-content-dt_reg_overfi"></a>Overfitting</p>
<ul>
<li>A major flaw of decision trees are their tendency to overfit the data. Because of this, we can <em>prune</em> or impose <em>stopping criteria</em>.
<ul>
<li>
<p><strong>Pruning</strong> (also referred to as <em>post-pruning</em>)
Grow the tree as deep as possible.  Then, for each terminal node, calculate the error associated with a tree that leaves the node as is. Then merge the two leaves and calculate the error from the resulting model.  If the overall model has a lower error rate, merge the leaves.</p>
</li>
<li>
<p><strong>Stopping Criteria</strong> (also referred to as <em>pre-pruning</em>)
Stop growing the tree once some stopping criteria are met.</p>
<ul>
<li>Minimum Leaf Size: Stop when the number of data points for a leaf gets below a threshold</li>
<li>Depth: Stop when the depth of the tree (distance from root to leaf) reaches a threshold</li>
<li>Loss: Stop when the RSS reduction isn't improved significantly</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><a name="user-content-dt_reg_hyperp"></a>Hyperparameters</p>
<ul>
<li>Minimum leaf size - some number of observations that each leaf needs to contain in order to prevent overfitting</li>
<li>depth - number of nodes between the root and final leaves</li>
<li>loss threshold - each split causes some decrease in sum of squares. We can assert that if the decrease is below some threshold, the split is not valuable enough to execute.</li>
</ul>
<p>"The preferred strategy is to grow a large tree T0, stopping the splitting
process only when some minimum node size (say 5) is reached. Then this
large tree is pruned using cost-complexity pruning" (see more: ISL 308)</p>
</li>
<li>
<p><a name="user-content-dt_reg_online"></a>Online</p>
<ul>
<li>The traditional decision tree model cannot use streaming data as all data is required when fitting the model.  However, there has been <a href="http://www.jmlr.org/papers/volume11/ben-haim10a/ben-haim10a.pdf" rel="nofollow">work</a> to modify the algorithm to allow for streaming data.</li>
</ul>
</li>
<li>
<p><a name="user-content-dt_reg_unqatt"></a>Unique attributes</p>
<ul>
<li>Easy to communicate</li>
<li>Strong in high dimensions (with pre / post pruning)</li>
<li>Robust to outliers</li>
<li>Mixed types of inputs (categorical / numerical)</li>
</ul>
</li>
<li>
<p><a name="user-content-dt_reg_spec_use_case"></a>Special use cases<br>
sklearn's decision tree learning models are a little finicky and require data be in a particular format.</p>
<ul>
<li><em>Missing</em> values have to be dealt with -- use surrogate variables</li>
<li><em>Categorical</em> variables need to be "dummified"</li>
</ul>
</li>
</ul>
<h4><a id="user-content-bagged-tree-regression" class="anchor" aria-hidden="true" href="#bagged-tree-regression"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Bagged Tree Regression</h4>
<p>Because regression trees have high variance (they overfit), we can apply the principles of <a href="https://en.wikipedia.org/wiki/Bootstrapping_(statistics)" rel="nofollow">bootstrapping</a> to create <em>bagged</em> trees.  When creating bagged trees, we create <em>B</em> decision trees trained on <em>B</em> bootstrapped training sets.  The trees are grown very deep and aren't pruned. The predicted value is the average value after predicting through all <em>B</em> trees. Each tree will have high variance but low bias.  Because we are averaging the values, we are, in effect, averaging the variance as well.  Thus, we can have a model that has low bias, and moderate variance.</p>
<p><a target="_blank" rel="noopener noreferrer" href="/GalvanizeDataScience/interview-prep/blob/master/review/images/ensemble.png"><img src="/GalvanizeDataScience/interview-prep/raw/master/review/images/ensemble.png" alt="Bagged Trees" style="max-width:100%;"></a></p>
<p>Below are the characteristics of differentiation between bagged trees and decision trees</p>
<ul>
<li>
<p><a name="user-content-bt_reg_inter"></a>Interpretability</p>
<ul>
<li>Finding feature importance in bagged trees is similar to a single decision tree, except the summation is across all bagged trees.</li>
</ul>
</li>
<li>
<p><a name="user-content-bt_reg_com"></a>Communication</p>
<ul>
<li>Bagged trees add two layers of complexity when communicating, <strong>multiple trees</strong> and <strong>bootstrapped training sets</strong>.  Explaining averaging the results of multiple trees isn't too cumbersome, but the reasoning for bootstrapping the training data is less straightforward.  See <a href="http://stats.stackexchange.com/questions/26088/explaining-to-laypeople-why-bootstrapping-works" rel="nofollow">here</a> for some different methods for explaining bootstrapping to laypeople.</li>
</ul>
</li>
<li>
<p><a name="user-content-bt_reg_viz"></a>Visualization</p>
<ul>
<li>Because there are now multiple trees, a single decision tree graph is no longer accurate.  You can show multiple trees and may also rely on a bar chart showing feature importance (ISL, 319).</li>
</ul>
</li>
<li>
<p><a name="user-content-bt_reg_eval"></a>Evaluation</p>
<ul>
<li>When bootstrapping, we only select (approx.) <a href="http://stats.stackexchange.com/questions/88980/why-on-average-does-each-bootstrap-sample-contain-roughly-two-thirds-of-observat" rel="nofollow">2/3 of the data</a>.  The ~1/3 of the data not used when building the tree is the "out-of-bag" data and can be viewed as a proxy "test set".  Thus, for each data point, there are ~<em>B</em>/3 trees constructed without that point.  We can calculate the error for that point by averaging the predictions of the <em>B</em>/3 trees.  Doing this across all data points yields an <strong>out-of-bag error</strong> (OOB).  The OOB characteristic of bagged models is a benefit because we don't have to hold out data when fitting our model--the model inherently does it (ISL, 318).</li>
</ul>
</li>
<li>
<p><a name="user-content-bt_reg_overfi"></a>Overfitting</p>
<ul>
<li>Bagging is a fix for overfitted decision trees.  However, you still need to tune the hyperparameters (see below) to optimize as much as possible.</li>
</ul>
</li>
<li>
<p><a name="user-content-bt_reg_hyperp"></a>Hyperparameters</p>
<ul>
<li>The pruning hyperparameters for decision trees are also available for the bagged trees--however, it is recommended that the trees in the bagged model are grown with minimal pruning (ISL, 317).</li>
<li><em>B</em> can be changed, but optimizing isn't necessary--choose a <em>B</em> that is sufficiently large (ISL, 317).</li>
</ul>
</li>
</ul>
<h4><a id="user-content-random-forest-regression" class="anchor" aria-hidden="true" href="#random-forest-regression"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Random Forest Regression</h4>
<p>The random forest is a decision tree learning model and is an extension from bagged decision trees that look to further reduce variance in the model.  Random forests are bagged decision tree models, except during training, each time we split, we reduce the available feature set on which to split from <em>p</em> total features to a random set of <em>m</em> features.  That means, that at each split the model doesn't even consider all of the features in the model.  The primary motivation for this is to introduce randomness into the fitting process so as to <em>decorrelate</em> the trees which make up the model.  Recall, that the motivation for bagging is to average away the variance that are inherent in a single decision tree. However, if there are a few strong predictors, then those will consistently be chosen at the top of the trees in the bagged model.  These trees will be highly correlated.  Averaging away variance only works when the items are decorrelated.  Thus, the motivation for limiting the potential features <strong>for each split</strong> to a random subset. (ISL, 320)</p>
<ul>
<li>
<p><a name="user-content-rfr_reg_high_dim"></a>High dimensionality</p>
<ul>
<li>Random forests are robust to high dimensional data.  However, if only a small fraction of features contain signal, a model fit with a small <em>m</em> will perform poorly.  In this case, <em>m</em> should be increased (ESL, 596)</li>
</ul>
</li>
<li>
<p><a name="user-content-rfr_reg_ts"></a>Training speed</p>
<ul>
<li>While decision trees are typically slow to train, by selecting subsets of the feature space, random forests significantly decrease training speed. (<a href="https://github.com/glouppe/phd-thesis/blob/master/thesis.pdf">pg. 95</a>.)</li>
</ul>
</li>
<li>
<p><a name="user-content-rfr_reg_ps"></a>Prediction speed</p>
<ul>
<li>Prediction speed is <a href="http://rexdouglass.com/fastest-random-forest-sklearn/" rel="nofollow">significantly faster</a> than training speed.</li>
</ul>
</li>
<li>
<p><a name="user-content-rfr_reg_inter"></a>Interpretability</p>
<ul>
<li>
<p>Finding feature importance in random forests is similar to a single decision tree, except the summation is across all trees.</p>
</li>
<li>
<p><a href="http://scikit-learn.org/stable/modules/ensemble.html#feature-importance-evaluation" rel="nofollow">sklearn's</a> <code>feature_importance_</code> attribute uses a different calculation.
Basically, the higher in the tree the feature is, the more important it is in determining the result of a data point.
The expected fraction of data points that reach a node is used as an estimate of that feature's importance for that tree.
Finally, average those values across all trees to get the feature's importance.</p>
</li>
</ul>
</li>
<li>
<p><a name="user-content-rfr_reg_com"></a>Communication</p>
<ul>
<li>Random forests are 3 levels of abstraction away from decision trees (bootstrapped training, multiple trees, random choice of features).  Focus communication on describing a single tree and then layer in the added complexity by emphasizing the goal is to make the model robust to overfitting.</li>
</ul>
</li>
<li>
<p><a name="user-content-rfr_reg_viz"></a>Visualization</p>
<ul>
<li>
<p>Variable importance charts are useful</p>
<p><a target="_blank" rel="noopener noreferrer" href="/GalvanizeDataScience/interview-prep/blob/master/review/images/feat_imp.png"><img src="/GalvanizeDataScience/interview-prep/raw/master/review/images/feat_imp.png" alt="Feature Importance" style="max-width:100%;"></a></p>
</li>
<li>
<p>It maybe also useful to present a few different trees (or the first few branches) which use different features for splitting.  Emphasize this is a subset of the forest.  This will illustrate its ensemble characteristic as well as punctuate that each tree can have a different set of important features.</p>
</li>
</ul>
</li>
<li>
<p><a name="user-content-rfr_reg_eval"></a>Evaluation</p>
<ul>
<li>See <a href="#bt_reg_eval">bootstrapping evaluation</a></li>
</ul>
</li>
<li>
<p><a name="user-content-rfr_reg_nl_p"></a>Nonlinearity</p>
<ul>
<li>Decision tree learning models are particularly strong at fitting nonlinear data (ISL, 106).</li>
</ul>
</li>
<li>
<p><a name="user-content-rfr_reg_big_n_small_p"></a>n &lt;&lt; p</p>
<ul>
<li>Small n, large p can cause problems for random forests, though there isn't universal <a href="http://stats.stackexchange.com/questions/48434/limits-to-tree-based-ensemble-methods-in-small-n-large-p-problems" rel="nofollow">consensus</a>.  <a href="http://arxiv.org/pdf/0811.3619.pdf" rel="nofollow">Page 10</a> shows bagging can outperform random forest in n &lt;&lt; p situations.</li>
</ul>
</li>
<li>
<p><a name="user-content-rfr_reg_outlier"></a>Outliers</p>
<ul>
<li>Handle outliers because made up of trees?</li>
</ul>
</li>
<li>
<p><a name="user-content-rfr_reg_overfi"></a>Overfitting</p>
<ul>
<li>While random forests improve on bagging and decision trees, they can still overfit. <a href="http://stats.stackexchange.com/questions/111968/random-forest-how-to-handle-overfitting" rel="nofollow">Cross validating</a> the tuning parameters should be done (ESL, 596).</li>
</ul>
</li>
<li>
<p><a name="user-content-rfr_reg_hyperp"></a>Hyperparameters (ESL, 592)</p>
<ul>
<li><em>m</em>, <em>minimum leaf size</em>, <em>depth</em>, and <em>loss</em> can and should be tuned using cross-validation (and if time permits, grid search cross-validation)</li>
<li>A rule of thumb <em>m</em> is p/3</li>
<li>A rule of thumb <em>minimum leaf size</em> is 5</li>
</ul>
</li>
<li>
<p><a name="user-content-rfr_reg_online"></a>Online</p>
<ul>
<li>The traditional random forest model cannot use streaming data as all data is required when fitting the model.  However, there has been <a href="http://research.cs.queensu.ca/home/cords2/ideas07.pdf" rel="nofollow">work</a> to modify the algorithm to allow for streaming data.</li>
</ul>
</li>
<li>
<p><a name="user-content-rfr_reg_spec_use_case"></a>Special use cases</p>
<ul>
<li>Because random forests are robust to wide and tall data, outliers, and overfitting they are attractive as first cut models.  When you need a place to start, try a random forest and build other model types based on the "free" learnings.</li>
</ul>
</li>
</ul>
<h4><a id="user-content-boosted-trees-regression" class="anchor" aria-hidden="true" href="#boosted-trees-regression"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Boosted Trees Regression<a name="user-content-boosted_trees_reg"></a></h4>
<ul>
<li>
<p>High dimensionality</p>
<ul>
<li>Works well, although we may need stopping criteria to prevent overfitting.</li>
</ul>
</li>
<li>
<p>Training speed</p>
</li>
<li>
<p>Prediction speed</p>
<ul>
<li>Fast.</li>
</ul>
</li>
<li>
<p>Interpretability</p>
<ul>
<li>Not all that interpretable. However, they might be slightly more interpretable compared to Random Forests. ISL: In boosting, because the growth of a particular tree takes into account the other trees that have already been grown, smaller trees are typically sufficient. Using smaller trees can aid in interpretability as well; for instance, using stumps leads to an additive model.</li>
</ul>
</li>
<li>
<p>Communication</p>
<ul>
<li>
<p>This is a Decision Tree based model, where the trees are grown sequentially. Each tree is trained on a modified version of the dataset used by its predecessor, and no use is made of bootstrapping.</p>
</li>
<li>
<p>AdaBoost (<a href="http://scikit-learn.org/stable/modules/ensemble.html#adaboost" rel="nofollow">sklearn documentation</a>): The core principle of AdaBoost is to fit a sequence of weak learners (i.e., models that are only slightly better than random guessing, such as small decision trees) on repeatedly modified versions of the data. The predictions from all of them are then combined through a weighted majority vote (or sum) to produce the final prediction. The data modifications at each so-called boosting iteration consist of applying weights w_1, w_2, ..., w_N to each of the training samples. Initially, those weights are all set to w_i = 1/N, so that the first step simply trains a weak learner on the original data. For each successive iteration, the sample weights are individually modified and the learning algorithm is reapplied to the reweighted data. At a given step, those training examples that were incorrectly predicted by the boosted model induced at the previous step have their weights increased, whereas the weights are decreased for those that were predicted correctly. As iterations proceed, examples that are difficult to predict receive ever-increasing influence. Each subsequent weak learner is thereby forced to concentrate on the examples that are missed by the previous ones in the sequence.</p>
</li>
<li>
<p>Gradient Boosting (ISL): "Given the current model, we fit a decision tree to the residuals from the model. That is, we fit a tree using the current residuals, rather than the outcome Y , as the response. We then add this new decision tree into the fitted function in order to update the residuals. Each of these trees can be rather small, with just a few terminal nodes, determined by the parameter d in the algorithm. By fitting small trees to the residuals, we slowly improve f in areas where it does not perform well. The shrinkage parameter lambda slows the process down even further, allowing more and different shaped trees to attack the residuals."</p>
</li>
</ul>
</li>
<li>
<p>Visualization</p>
</li>
<li>
<p>Evaluation</p>
<ul>
<li>Standard metrics for regression/classification.</li>
</ul>
</li>
<li>
<p>Nonlinearity</p>
<ul>
<li>As a decision tree-based model,works well with non-linear data.</li>
</ul>
</li>
<li>
<p>n &lt;&lt; p</p>
<ul>
<li>Will work well provided we use early stopping.</li>
</ul>
</li>
<li>
<p>Outliers</p>
<ul>
<li>Robust to outliers.</li>
</ul>
</li>
<li>
<p>Overfitting</p>
<ul>
<li>Can overfit if the number of trees is too large.</li>
</ul>
</li>
<li>
<p>Hyperparameters</p>
<ul>
<li>The number of trees B.</li>
<li>The shrinkage parameter lambda. This controls the rate at which boosting learns.</li>
<li>The number d of splits in each tree, which controls the complexity of the boosted ensemble.</li>
</ul>
</li>
<li>
<p>Online</p>
<ul>
<li>No. All data is required to make the splits and as each tree is also trained sequentially, it is impossible to do this online.</li>
</ul>
</li>
<li>
<p>Unique attributes</p>
<ul>
<li>Makes a strong learner from weak learners.</li>
<li>A major disadvantage is scalability. Due to its sequential nature, it cannot be parallelized.</li>
</ul>
</li>
<li>
<p>Special use cases</p>
<ul>
<li>Boosted trees are powerful and usually outperform Bagging and Random Forests.</li>
</ul>
</li>
</ul>
<h2><a id="user-content-classification" class="anchor" aria-hidden="true" href="#classification"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Classification</h2>
<p>Many of the regression models can be used as classification models.  When this is the case, for the sake of brevity, only differences and notable characteristics will be emphasized.</p>
<h4><a id="user-content-logistic-regression" class="anchor" aria-hidden="true" href="#logistic-regression"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Logistic Regression</strong></h4>
<p>Logistic regression is the most widely used general-purpose classifier.  In linear regression, features are used to predict the value of a continuous outcome. The coefficient vector represents the change in the predicted value for one unit of change in the feature.  In logistic regression, features are used to predict the <strong>probabilities of incoming data belonging to a particular class</strong>. The coefficient vector represents the change in the logit function for one unit of change in the feature.</p>
<ul>
<li>
<p>High dimensionality</p>
</li>
<li>
<p>As with linear regression, logistic regression is prone to overfitting when using a large number of features.  Subset selection, regularization, and dimensionality reduction can all be used to reduce the dimensions.</p>
</li>
<li>
<p>Training speed</p>
<ul>
<li>Depends on the size of the data, but generally a fast model to train.  <a href="http://scikit-learn.org/stable/modules/sgd.html#classification" rel="nofollow">Stochastic gradient descent</a> can be used to speed up training when training on more than 10,000 points</li>
</ul>
</li>
<li>
<p>Prediction speed</p>
<ul>
<li>Predictions are very fast as they are merely the dot product of the coefficient vector and the input matrix.</li>
</ul>
</li>
<li>
<p>Interpretability</p>
<ul>
<li>
<p>The odds ratio tells you how much a one unit increase of a feature increases the odds of being classified in the positive class. The coefficients of logistic regression models are the odds ratio and can be interpreted similarly to that of linear regression (ISL, 132).</p>
</li>
<li>
<p>Similar to linear regression, the coefficients could be interpreted to indicate the importance of the factors, but you have to be careful about putting the data on a uniform scale and about losing the one unit increase explanation.
<code>Note most of the time we don't put things on a uniform scale, in which case you can't interpret importance via magnitude of the coefficients.</code></p>
</li>
</ul>
</li>
<li>
<p>Communication</p>
<ul>
<li>Logistic regression predicts the probability that a given point belongs to the "positive" class.  Therefore, the model will predict if the point is from the positive class when the probability is greater than you threshold (usually 0.5) (ISL, 134).</li>
</ul>
</li>
<li>
<p>Visualization</p>
<ul>
<li>For a model with a single predictor, you can plot the training data, colored by class value.  All positive labels will be on the line y=1 and all negative labels will be on the line y=0.  Then plot the sigmoid curve (model) as well as the horizontal probability threshold (usually y=0.50).  The intersection of the sigmoid curve and the probability threshold line will represent the <em>decision boundary</em>.  X values greater than the intersection will be predicted as a positive class.</li>
</ul>
<p><a target="_blank" rel="noopener noreferrer" href="/GalvanizeDataScience/interview-prep/blob/master/review/images/logit_basic.png"><img src="/GalvanizeDataScience/interview-prep/raw/master/review/images/logit_basic.png" alt="Logistic Regression" style="max-width:100%;"></a></p>
<ul>
<li>If the model has 2 predictors, you can again plot the training data colored by class value, but the x-axis will be one predictor and the y-axis will be the other.  Then, plot the <em>decision boundary</em> line.  Predicted values above the decision boundary will be labeled as the majority class also above the line.</li>
</ul>
<p><a target="_blank" rel="noopener noreferrer" href="/GalvanizeDataScience/interview-prep/blob/master/review/images/dec_boundary.png"><img src="/GalvanizeDataScience/interview-prep/raw/master/review/images/dec_boundary.png" alt="Decision Boundary" style="max-width:100%;"></a></p>
</li>
<li>
<p><a name="user-content-clas_eval"></a>Evaluation (these apply to all classification algorithms)</p>
<ul>
<li>For all supervised learning algorithms, we care most of all about generalization on unseen data. That means that during prototyping and model iteration, k-fold cross validation should be what we're aiming to optimize, and in the end, the evaluation metric we care about is performance on hold-out test data.</li>
<li><a href="https://en.wikipedia.org/wiki/F1_score" rel="nofollow">F1</a> - The harmonic mean of precision and recall. Basically, a metric that rewards correctly labeled positive values while penalizing incorrectly labeled positive values.</li>
</ul>
<p><a target="_blank" rel="noopener noreferrer" href="/GalvanizeDataScience/interview-prep/blob/master/review/images/f1.png"><img src="/GalvanizeDataScience/interview-prep/raw/master/review/images/f1.png" alt="F1" style="max-width:100%;"></a></p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Precision_and_recall" rel="nofollow">Precision</a> aka <em>Positive Predictive Value (PPV)</em> - The proportion of correctly predicted positive labels to all predicted positive labels.</li>
</ul>
<p><a target="_blank" rel="noopener noreferrer" href="/GalvanizeDataScience/interview-prep/blob/master/review/images/precision.png"><img src="/GalvanizeDataScience/interview-prep/raw/master/review/images/precision.png" alt="Precision" style="max-width:100%;"></a></p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Precision_and_recall" rel="nofollow">Recall / Sensitivity</a> aka <em>True Positive Rate (TPR)</em> - The proportion of correctly predicted positive labels to all actual positive labels.</li>
</ul>
<p><a target="_blank" rel="noopener noreferrer" href="/GalvanizeDataScience/interview-prep/blob/master/review/images/recall.png"><img src="/GalvanizeDataScience/interview-prep/raw/master/review/images/recall.png" alt="Recall" style="max-width:100%;"></a></p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Sensitivity_and_specificity" rel="nofollow">Specificity</a> aka <em>True Negative Rate (TNR)</em> - The proportion of correctly predicted negative labels to all actual negative labels.</li>
</ul>
<p><a target="_blank" rel="noopener noreferrer" href="/GalvanizeDataScience/interview-prep/blob/master/review/images/specificity.png"><img src="/GalvanizeDataScience/interview-prep/raw/master/review/images/specificity.png" alt="Specificity" style="max-width:100%;"></a></p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Sensitivity_and_specificity" rel="nofollow">Fall Out</a> aka <em>False Positive Rate(FPR)</em> - The proportion of incorrectly predicted positive labels to all actual negative labels. 1 - Specificity</li>
</ul>
<p><a target="_blank" rel="noopener noreferrer" href="/GalvanizeDataScience/interview-prep/blob/master/review/images/fallout.png"><img src="/GalvanizeDataScience/interview-prep/raw/master/review/images/fallout.png" alt="Fall Out" style="max-width:100%;"></a></p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Sensitivity_and_specificity" rel="nofollow">Accuracy</a> - The proportion of correctly predicted positive and negative labels to all actual labels.</li>
</ul>
<p><a target="_blank" rel="noopener noreferrer" href="/GalvanizeDataScience/interview-prep/blob/master/review/images/accuracy.png"><img src="/GalvanizeDataScience/interview-prep/raw/master/review/images/accuracy.png" alt="Accuracy" style="max-width:100%;"></a></p>
<ul>
<li>
<p><a href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic" rel="nofollow">Receiver Operator Characteristic (ROC) curve</a> - Illustrates the trade-off between sensitivity (TPR) and the Fall Out (FPR) as the prediction threshold changes.</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve" rel="nofollow">Area Under The Curve (AUC/AUROC)</a> is equal to the probability that the model will rank a randomly chosen positive instance higher than a randomly chosen negative instance.  AUC should be used with caution when comparing models.</li>
</ul>
</li>
</ul>
<p><a target="_blank" rel="noopener noreferrer" href="/GalvanizeDataScience/interview-prep/blob/master/review/images/roc_curve.png"><img src="/GalvanizeDataScience/interview-prep/raw/master/review/images/roc_curve.png" alt="Roc Curve" style="max-width:100%;"></a></p>
</li>
<li>
<p>Nonlinearity</p>
<ul>
<li>Since logistic regression is essentially linear regression in a sigmoid curve, we can model nonlinearity in the <a href="#lr_nl_power">same way</a>.</li>
</ul>
</li>
<li>
<p>n &lt;&lt; p</p>
<ul>
<li>See <a href="#lr_big_n_small_p">linear regression</a>.</li>
</ul>
</li>
<li>
<p>Outliers</p>
</li>
<li>
<p>Overfitting</p>
<ul>
<li>See linear regressing <a href="#lr_overfitting">overfitting</a> and ways to <a href="#lr_subset">prevent it</a>.</li>
</ul>
</li>
<li>
<p><a href="http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html" rel="nofollow">Hyperparameters</a></p>
<ul>
<li>Threshold for positive classification (typically 0.5)</li>
<li>Class weighting for unbalanced classes</li>
<li>Parameters for <a href="http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier" rel="nofollow">gradient descent</a>:
<ul>
<li>Step size</li>
<li>Stopping criterion: minimum change in error or number of iterations</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Online</p>
<ul>
<li>Can be updated online through <a href="https://en.wikipedia.org/wiki/Online_machine_learning#Stochastic_Gradient_Descent" rel="nofollow">stochastic gradient descent</a>.</li>
</ul>
</li>
<li>
<p>Unique attributes</p>
<ul>
<li>
<p>The output of logistic regression can be interpreted as a probability of classification.</p>
</li>
<li>
<p>Scale the data if you want the coefficients to give you some indication of feature importance.</p>
</li>
</ul>
</li>
<li>
<p>Special use cases</p>
<ul>
<li><a name="user-content-class_imbalance"></a><strong>Class Imbalance</strong>
<ul>
<li>Class Imbalance occurs when one of the classes rarely occurs in the data set.  While imbalanced classes are not outliers, their presence must be detected early to ensure we are evaluating the model properly. An example is credit fraud in a transaction log--the vast majority of transactions are not fraudulent and it could likely be less than 1% of observations.  A stupid model that always predicts "not fraud" would therefore have a 99% accuracy.  There are some steps that can be taken to alleviate some of the issues present in class imbalance.
<ul>
<li>Oversampling
<ul>
<li>Replicate samples in smaller class</li>
<li>Can cause overfitting because noise is replicated</li>
<li>Can generate new examples in neighborhood of observations</li>
</ul>
</li>
<li>Undersampling
<ul>
<li>subsample from larger class repeatedly and ensemble classifiers</li>
</ul>
</li>
<li>Can combine over- and under-sampling</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4><a id="user-content-k-nearest-neighbors-classifier" class="anchor" aria-hidden="true" href="#k-nearest-neighbors-classifier"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>k-Nearest Neighbors Classifier</h4>
<p>Similar to <a href="#k-nearest-neighbors-regression">k-nearest neighbors regression</a> with the exception that the predicted value is the <strong>most common (mode)</strong> class of the nearest neighbors.  Other differences are noted below.</p>
<ul>
<li>Evaluation
<ul>
<li>See <a href="#clas_eval">logistic regression classifiers</a>.
ROC curves are inapplicable</li>
</ul>
</li>
</ul>
<h4><a id="user-content-decision-tree-classifier" class="anchor" aria-hidden="true" href="#decision-tree-classifier"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Decision Tree Classifier</h4>
<p>Similar to <a href="#decision-tree-regression">decision tree regression</a> with the exception that the predicted value is the <strong>most common (mode)</strong> class of the terminal node (leaf).  Other differences are noted below.</p>
<ul>
<li>
<p>Evaluation</p>
<ul>
<li>While decision tree regression typically uses RSS to fit the model, this is inapplicable in a classification setting.  The two most common loss metrics for classification are <strong>information gain</strong> and <strong>gini impurity</strong>.
<ul>
<li><strong>Information Gain</strong> tries to minimize the <em>entropy</em> in the system (in this case the data in the preceding node) at each split.  When determining the best split <em>at that point</em>, all features are evaluated, and the feature which creates a split that decreases the entropy the most <em>at that point</em> is chosen.
<ul>
<li><strong>Entropy</strong> is a measure of disorder within a system.  Intuitively, systems which have near uniform classes will have low entropy and the entropy grows as the mix becomes more heterogeneous.</li>
</ul>
</li>
<li><a href="https://en.wikipedia.org/wiki/Decision_tree_learning#Gini_impurity" rel="nofollow">Gini Impurity</a> (a.k.a Gini Index) is another measure of heterogeneity. It is the probability of misclassifying a randomly drawn point when guessing its label based on the known class proportions (ISL, 312).</li>
</ul>
</li>
<li>For choosing between models, see the metrics in <a href="#clas_eval">logistic regression classifiers</a>.  ROC curves are inapplicable because decision trees predict classes rather than probabilities.
<ul>
<li><em>sklearn</em> has a <a href="http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier.predict_proba" rel="nofollow">method</a> to calculate the "probabilities".  This is not actually probability, rather it is the <a href="http://stats.stackexchange.com/questions/105760/how-we-can-draw-an-roc-curve-for-decision-trees" rel="nofollow">percentage</a> of observations in the terminal node from the majority class.</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Overfitting</p>
<ul>
<li>See <a href="#dt_reg_overfi">Decision Tree regression</a>
* <strong>Stopping Criteria</strong>: In addition to the decision tree regression stopping hyperparameters, classification trees have:<br>
* Mostly the Same: Stop when some percent of the data points are the same (rather than all the same)
* Error threshold: Stop when the error reduction (information gain) isn't improved significantly. (<em>Instead of loss</em>)</li>
</ul>
</li>
<li>
<p>Hyperparameters</p>
<ul>
<li>See <a href="#dt_reg_hyperp">Decision Tree regression</a><br>
Additionally, there is  <em>mostly the same</em> and <em>error threshold</em> (instead of <em>loss</em>).</li>
</ul>
</li>
<li>
<p>Special use cases</p>
<ul>
<li>See <a href="#class_imbalance">Class Imbalance</a></li>
</ul>
</li>
</ul>
<h4><a id="user-content-bagged-tree-classifier" class="anchor" aria-hidden="true" href="#bagged-tree-classifier"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Bagged Tree Classifier</h4>
<p>Similar to bagged tree regression with the exception that the predicted value is the <strong>most common (mode)</strong> class of the predictions from each tree.  Other differences are noted below.</p>
<ul>
<li>Evaluation
<ul>
<li>See <a href="#clas_eval">logistic regression classifiers</a></li>
<li>See <a href="#bt_reg_eval">Bagged Tree regression</a> for OOB-error explanation</li>
</ul>
</li>
</ul>
<h4><a id="user-content-random-forest-classifier" class="anchor" aria-hidden="true" href="#random-forest-classifier"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Random Forest Classifier</h4>
<p>Similar to <a href="#random-forest-regression">random forest regression</a> with the exception that the predicted value is the <strong>most common (mode)</strong> class of the predictions from each tree.  Other differences are noted below.</p>
<ul>
<li>
<p>Hyperparameters</p>
<ul>
<li>See <a href="#rfr_reg_hyperp">Random Forest regression</a> with the following differences (ESL, 592):
<ul>
<li>A rule of thumb <em>m</em> is sqrt(p)</li>
<li>A rule of thumb <em>minimum leaf size</em> is 1</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Special use cases</p>
<ul>
<li>See <a href="#rfr_reg_spec_use_case">Random Forest regression</a></li>
<li>See <a href="#class_imbalance">Class Imbalance</a></li>
</ul>
</li>
</ul>
<h4><a id="user-content-boosted-trees-classifier" class="anchor" aria-hidden="true" href="#boosted-trees-classifier"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Boosted Trees Classifier</h4>
<ul>
<li>See <a href="#boosted-trees-regression">Boosted Trees Regression</a></li>
</ul>
<h4><a id="user-content-svm" class="anchor" aria-hidden="true" href="#svm"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>SVM</h4>
<ul>
<li>
<p>High dimensionality</p>
<ul>
<li>Work well.</li>
</ul>
</li>
<li>
<p>Training speed</p>
<ul>
<li>Very slow.</li>
</ul>
</li>
<li>
<p>Prediction speed</p>
<ul>
<li>Fast. We only need to compute the kernel between the point and the support vectors.</li>
</ul>
</li>
<li>
<p>Interpretability</p>
<ul>
<li>Not interpretable. Support Vectors are vectors near the margin - they give us no information about the features.</li>
</ul>
</li>
<li>
<p>Communication</p>
<ul>
<li>SVMs find a boundary between classes and try to find the largest possible margin. This margin is supported by points which are called "Support Vectors". The maximum margin classifier needs strictly separable data. SVMs can learn decision boundaries for non-separable data, when we allow for misclassification. The width of the margin then depends on the number of points we allow to be misclassified. For prediction, we only need to compute the kernel between the support vectors and the new point, which makes for extremely fast predictions.</li>
</ul>
</li>
<li>
<p>Visualization</p>
<ul>
<li>Easy to visualize for 2-D or 3-D data, not otherwise.</li>
</ul>
<p><a target="_blank" rel="noopener noreferrer" href="/GalvanizeDataScience/interview-prep/blob/master/review/images/svm2.PNG"><img src="/GalvanizeDataScience/interview-prep/raw/master/review/images/svm2.PNG" alt="svm decision boundary" style="max-width:100%;"></a></p>
</li>
<li>
<p>Evaluation</p>
<ul>
<li>Standard metrics for classification problems: Accuracy, Precision/Recall, F1-score.</li>
</ul>
</li>
<li>
<p>Nonlinearity</p>
<ul>
<li>Using non-linear kernels enables it to learn non-linear decision boundaries.</li>
</ul>
</li>
<li>
<p>n &lt;&lt; p</p>
<ul>
<li>Only linear kernel might work (<strong>or will it?</strong>). More complex kernels will be prone to overfitting.</li>
</ul>
</li>
<li>
<p>Outliers</p>
<ul>
<li>Not susceptible to outliers. Only support vectors determine the separation hyperplane, and the margin width is determined by points closest to the plane.</li>
</ul>
</li>
<li>
<p>Overfitting</p>
<ul>
<li>Prone to overfitting, if we force the margin to be too small (i.e. allow too few misclassifications).</li>
</ul>
</li>
<li>
<p>Hyperparameters</p>
<ul>
<li>Margin-width (C-parameter) and kernel parameters (gamma, degree)</li>
</ul>
</li>
<li>
<p>Online</p>
<ul>
<li>No. Theoretically, if the point does not lie within the margin, we could. Otherwise, we would need to recompute the margin. But we don't know where the point lies, so it is impossible to train online.</li>
</ul>
</li>
<li>
<p>Unique attributes</p>
<ul>
<li>Scaling is necessary, else features with larger ranges gain more weight.</li>
<li>Able to learn complex decision boundaries.</li>
</ul>
</li>
<li>
<p>Special use cases</p>
<ul>
<li>Works well with most classification problems.</li>
</ul>
</li>
</ul>
<h4><a id="user-content-neural-networks-with-one-hidden-layer" class="anchor" aria-hidden="true" href="#neural-networks-with-one-hidden-layer"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Neural Networks (with one hidden layer)</h4>
<ul>
<li>
<p>High dimensionality</p>
<ul>
<li>Works well, but will take longer to train. Typically in case of image classification, dimensionality reduction methods are used for faster training.</li>
</ul>
</li>
<li>
<p>Training speed</p>
<ul>
<li>Very slow.</li>
</ul>
</li>
<li>
<p>Prediction speed</p>
<ul>
<li>Fast - only depends on (h + 1) matrix multiplications, where h is the number of hidden layers. Although depending on the size of the matrices (which in turn depend on the number of features and the size of the hidden layer), this time could be longer than other models.</li>
</ul>
</li>
<li>
<p>Interpretability</p>
<ul>
<li>Not interpretable.</li>
</ul>
</li>
<li>
<p>Communication</p>
<ul>
<li>Quoting directly from <em>Elements of Statistical Learning</em>: Neural Networks were first developed as models for the human brain. Each unit represents a neuron, and the connections represent synapses. The neurons fired when the total signal passed to that unit exceeded a certain threshold. In earlier models a step function was used, which was later modified to sigmoid so that we have a differentiable function for optimization.</li>
</ul>
</li>
<li>
<p>Visualization</p>
<p><a target="_blank" rel="noopener noreferrer" href="/GalvanizeDataScience/interview-prep/blob/master/review/images/nnet.png"><img src="/GalvanizeDataScience/interview-prep/raw/master/review/images/nnet.png" alt="neuralnet" style="max-width:100%;"></a></p>
</li>
<li>
<p>Evaluation</p>
<ul>
<li>When used for classification - the standard metrics for classification: Accuracy, Precision, Recall, F1-score.</li>
</ul>
</li>
<li>
<p>Nonlinearity</p>
<ul>
<li>Very powerful, if trained correctly. Can learn any decision boundary.</li>
</ul>
</li>
<li>
<p>n &lt;&lt; p</p>
<ul>
<li>Will tend to overfit.</li>
</ul>
</li>
<li>
<p>Outliers</p>
<ul>
<li>Sensitive to outliers.</li>
</ul>
</li>
<li>
<p>Overfitting</p>
<ul>
<li>Prone to overfitting. From <em>Elements of Statistical Learning</em>: "The model is generally overparametrized, and the optimization problem is nonconvex and unstable unless certain guidelines are followed." The guidelines refer to 'early stopping' - where we can use a validation set to stop training before reaching the global minimum, or to use 'weight decay', which is essentially regularization.</li>
</ul>
</li>
<li>
<p>Hyperparameters</p>
<ul>
<li>Number of hidden layers. Number of units in the hidden layer.</li>
<li>Early stopping criteria or Weight decay parameters to prevent overfitting.</li>
</ul>
</li>
<li>
<p>Online</p>
<ul>
<li>Yes, via stochastic gradient descent.</li>
</ul>
</li>
<li>
<p>Unique attributes</p>
<ul>
<li>This is one case where we do not like to reach global minimum as it leads to overfitting.</li>
<li>Standardizing inputs in necessary.</li>
</ul>
</li>
<li>
<p>Special use cases</p>
<ul>
<li>Especially suited for Image classification.</li>
</ul>
</li>
</ul>
<h4><a id="user-content-naive-bayes" class="anchor" aria-hidden="true" href="#naive-bayes"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Naive Bayes</h4>
<ul>
<li>
<p>High dimensionality</p>
<ul>
<li>Can handle an arbitrary number of independent features - both continuous and/or categorical</li>
</ul>
</li>
<li>
<p>Training speed</p>
<ul>
<li>One of the fastest learning models. <a href="http://jaquesgrobler.github.io/Online-Scikit-Learn-stat-tut/modules/naive_bayes.html" rel="nofollow">NB on sklearn</a>: "The decoupling of the class conditional feature distributions means that each distribution can be independently estimated as a one dimensional distribution. This in turn helps to alleviate problems stemming from the curse of dimensionality."</li>
</ul>
</li>
<li>
<p>Prediction speed</p>
<ul>
<li>High</li>
</ul>
</li>
<li>
<p>Interpretability</p>
</li>
<li>
<p>Communication</p>
<ul>
<li>Naive Bayes is a simple model commonly used for classification in NLP tasks. It predicts the posterior probabilities p(y|x) by estimating p(x|y) and p(y) (using MLE), making it a generative model. It is "naive" because it assumes that the features are independent of each other. However, without this assumption, it is impossible to learn the probabilities as the number of parameters is too large. This simplification enables it to work with a large number of features, even as the number of features exceeds the number of data points.</li>
</ul>
</li>
<li>
<p>Visualization</p>
<ul>
<li>Result of classification using Naive Bayes:</li>
</ul>
<p>![naive bayes decision boundary](images/NB bdy.png)</p>
<ul>
<li>From <a href="http://www.cs.ucr.edu/~eamonn/CE/Bayesian%20Classification%20withInsect_examples.pdf" rel="nofollow">here</a>.</li>
</ul>
</li>
<li>
<p>Evaluation</p>
<ul>
<li>The standard metrics for classification such as accuracy, precision, recall, F1-score etc.</li>
</ul>
</li>
<li>
<p>Nonlinearity</p>
<ul>
<li>Can learn both linear and non-linear boundaries. The non-linear boundaries are however smooth, as naive Bayes is not prone to overfitting.</li>
</ul>
</li>
<li>
<p>n &lt;&lt; p</p>
<ul>
<li>Works well in this case.</li>
</ul>
</li>
<li>
<p>Outliers</p>
<ul>
<li>Is not very sensitive to outliers. The probability p(x_outlier | y) will be small.</li>
</ul>
</li>
<li>
<p>Overfitting</p>
<ul>
<li>Naive Bayes is a high bias model, it typically does not overfit.</li>
</ul>
</li>
<li>
<p>Hyperparameters</p>
<ul>
<li>will depend on the distribution we choose for p(x|y).
<ul>
<li>mean and variance for Gaussian</li>
<li>smoothing parameter/alpha, for Multinomial</li>
</ul>
</li>
<li>In addition, we can set class prior probabilities if we do not want to use the Maximum Likelihood estimate.</li>
</ul>
</li>
<li>
<p>Online</p>
<ul>
<li>Good at online learning. If using multinomial naive Bayes, stores counts (instead of probabilities), which can be easily updated.</li>
</ul>
</li>
<li>
<p>Unique attributes</p>
<ul>
<li>Naive Bayes is a generative model -- the only generative model in this list. We predict the joint probability p(y,x) instead of estimating the conditional probability p(y|x). Do not confuse naive bayes for a discriminative model just because the joint probability is THEN USED to calculate the conditional probability.</li>
<li>Naive Bayes works well with imbalanced classes.</li>
<li>Naive Bayes is insensitive to irrelevant features.</li>
<li>GaussianNB gives a <a href="http://www.cs.ucr.edu/~eamonn/CE/Bayesian%20Classification%20withInsect_examples.pdf" rel="nofollow">piecewise quadratic decision boundary</a>. These are less complex than say the boundaries learned by knn, svm or neural nets.</li>
</ul>
</li>
<li>
<p>Special use cases</p>
<ul>
<li>Works particularly well in NLP tasks such as document classification or spam filtering. Also works well with imbalanced classes.</li>
</ul>
</li>
</ul>
<h2><a id="user-content-unsupervised-learning" class="anchor" aria-hidden="true" href="#unsupervised-learning"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Unsupervised Learning</h2>
<h4><a id="user-content-k-means-clustering" class="anchor" aria-hidden="true" href="#k-means-clustering"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>k-means Clustering</h4>
<ul>
<li>
<p>High dimensionality</p>
<ul>
<li>k-means clustering relies on (squared) euclidean distance, and therefore suffers from the curse of dimensionality, as distance becomes less meaningful</li>
</ul>
</li>
<li>
<p>Training speed</p>
</li>
<li>
<p>Prediction speed</p>
<ul>
<li>No real "predictions" possible in unsupervised learning</li>
<li>To assign the cluster of a new point: very fast, only need to find k distances, much faster than training.</li>
</ul>
</li>
<li>
<p>Interpretability</p>
<ul>
<li>It is not possible to interpret which features are most important, as they all have the same weight when determing distance between clusters. Interpreting the results should instead focus on deriving insight about the kinds of observations one has.</li>
<li>Useful as a guide to begin understanding one's data; should not be accepted as hard truth (ISL 401)</li>
</ul>
</li>
<li>
<p>Communication</p>
<ul>
<li>K-means clustering aims to segment the data into some number of groups such that each point is as close to the center of its group as possible. The objective is to find the right number of groups, and the right centers, so that this is achieved.</li>
</ul>
</li>
<li>
<p>Visualization</p>
<ul>
<li>K-means is easily visualized in 2D or 3D space. Somewhat uniquely, you can also easily visualize the algorithm at each step to help explain it.</li>
<li>Algorithm at work (click/refresh to play):</li>
</ul>
</li>
</ul>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/zipfian/solns/blob/master/images/kmeans.gif"><img src="https://github.com/zipfian/solns/raw/master/images/kmeans.gif" alt="kmeans.gif" style="max-width:100%;"></a></p>
<ul>
<li>Visualization of results:</li>
</ul>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/zipfian/solns/blob/master/images/kmeans_2d.png"><img src="https://github.com/zipfian/solns/raw/master/images/kmeans_2d.png" alt="kmeans_2d.png" style="max-width:100%;"></a></p>
<ul>
<li>
<p>Evaluation</p>
<ul>
<li>Unsupervised learning is difficult to evaluate. There's no standard accepted way to evaluate clusters, though some techniques are proposed. (ISL 400)</li>
</ul>
</li>
<li>
<p>Nonlinearity</p>
<ul>
<li>
<p>The decision boundaries between clusters are depicted by straight lines, producing a Voronoi tesselation (ESL 510). Therefore, K-Means performs poorly on data with clusters that are non-linearly separable:</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/zipfian/solns/blob/master/images/k-means_fail.jpg"><img src="https://github.com/zipfian/solns/raw/master/images/k-means_fail.jpg" alt="k-means_fail.jpg" style="max-width:100%;"></a></p>
</li>
</ul>
</li>
<li>
<p>n &lt;&lt; p</p>
<ul>
<li>Results will suffer when there are more predictors than data points. The distance measures become less meaningful if you have sparse, high-dimensional data due to curse of dimensionality</li>
</ul>
</li>
<li>
<p>Outliers</p>
<ul>
<li>The distance used is Euclidean squared, so K-Means isn't robust to outliers. Consider K-Medioids (ESL 515 14.3.10)</li>
</ul>
</li>
<li>
<p>Overfitting</p>
<ul>
<li>Be aware at any point that you may just be "clustering the noise" (ISL 400). If k is too large, your clusters are too small to have interprable meaning.</li>
</ul>
</li>
<li>
<p>Hyperparameters</p>
<ul>
<li>position of starting centroids (often randomized)</li>
<li>number of iterations (often until stability is found)</li>
<li>number of clusters k
<ul>
<li>This is sometimes defined by your problem statement, or sometimes something that needs to be optimized if clustering is being used as a descriptive tool.</li>
<li>To determine K, some possible techniques:
<ul>
<li>elbow method - look at percentage of variance explained at each K, select one such that adding more clusters doesn't much improve the model</li>
<li>gap-statistic - see ESL 518</li>
<li>Silhouette Coefficient (see DSI clustering slides appendix)</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Online</p>
<ul>
<li>yes, just need to maintain counts for each cluster as well as cluster centers, can easily calculate new centroid with one new point. (<a href="http://ocw.mit.edu/courses/sloan-school-of-management/15-097-prediction-machine-learning-and-statistics-spring-2012/projects/MIT15_097S12_proj1.pdf" rel="nofollow">see more</a>)</li>
</ul>
</li>
<li>
<p>Unique attributes</p>
<ul>
<li>designed for cases where all variables are quantitative (ESL 509)</li>
<li>requires you to pre-specify k</li>
<li>Altering the value of K doesn't preserve your present results in a meaningful way, and can change cluster membership in "arbitrary ways" (ESL 514), as opposed to neatly nested clusters as in hierarchical clustering.</li>
</ul>
</li>
<li>
<p>Special use cases</p>
<ul>
<li>won't work well if "true" clusters are different sizes/densities</li>
<li>important to normalize data first so that distance metrics aren't dominated by variables with larger units</li>
</ul>
</li>
</ul>
<p>####Hierarchical Clustering</p>
<ul>
<li>
<p>High dimensionality</p>
<ul>
<li>hierarchical clustering depends entirely on distance/similarity measures, and therefore suffers from the curse of dimensionality, as distance becomes less meaningful in higher dimensions.</li>
</ul>
</li>
<li>
<p>Training speed</p>
</li>
<li>
<p>Prediction speed</p>
<ul>
<li>No real "predictions" possible in unsupervised learning</li>
<li>To assign the cluster of a new point: very fast, only need to find k distances, much faster than training.</li>
</ul>
</li>
<li>
<p>Interpretability</p>
<ul>
<li>It is not possible to interpret which features are most important, as they all have the same weight when determing distance between clusters. Interpreting the results should instead focus on deriving insight about the kinds of data points one has.</li>
<li>Useful as a guide to begin understanding one's data; should not be accepted as hard truth (ISL 401)</li>
</ul>
</li>
<li>
<p>Communication</p>
<ul>
<li>Hierarchical clustering arranges items in a hierarchy with a treelike structure based on the distance or similarity between them. Start with n clusters, each with one of your n data points, and one-by-one combine the closest clusters until you end up with one big cluster of all data points.</li>
</ul>
</li>
<li>
<p>Visualization</p>
<ul>
<li>The results of hierarchical clustering are visualized with a binary-tree structure called a dendrogram: (ESL 521)</li>
</ul>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/zipfian/solns/blob/master/images/dendrogram.png"><img src="https://github.com/zipfian/solns/raw/master/images/dendrogram.png" alt="dendrogram.png" style="max-width:100%;"></a></p>
<ul>
<li>The vertical distance between clusters represents the dissimilarity between them, making it highly interpretable.</li>
<li>Each "leaf" of the tree is a single observation, and as we move upwards, we can see observations fuse into clusters, which fuse into larger clusters and so on until we end up with one cluster of all observations. (ISL 391)</li>
</ul>
</li>
<li>
<p>Evaluation</p>
<ul>
<li>Unsupervised learning is difficult to evaluate. There's no standard accepted way to evaluate clusters, though some techniques are proposed. (ISL 400)</li>
</ul>
</li>
<li>
<p>Nonlinearity</p>
<ul>
<li>Without any modifications, hierarchical clustering, like k-means, performs poorly on non-linearly separable clusters. <a href="http://scikit-learn.org/stable/auto_examples/cluster/plot_ward_structured_vs_unstructured.html" rel="nofollow">See more here.</a></li>
</ul>
</li>
<li>
<p>n &lt;&lt; p</p>
<ul>
<li>Results will suffer when there are more predictors than data points. The distance measures become less meaningful if you have sparse, high-dimensional data due to curse of dimensionality</li>
</ul>
</li>
<li>
<p>Outliers</p>
<ul>
<li>Like k-means, hierarchical clustering necessarily assigns EACH point to a cluster. Outliers will exert undue influence over final clusters. (ISL 400)</li>
</ul>
</li>
<li>
<p>Overfitting</p>
<ul>
<li>Be aware at any point that you may just be "clustering the noise" (ISL 400). If k is too large, your clusters are too small to have interprable meaning.</li>
</ul>
</li>
<li>
<p>Hyperparameters</p>
<ul>
<li>Dissimilarity measure (often Euclidean distance, see ISL 396)</li>
<li>Linkage -- which dissimilarity to use between clusters of several observations?
<ul>
<li>Complete -- max pairwise distance</li>
<li>Single -- min pairwise distance</li>
<li>Average -- mean pairwise distance</li>
<li>Centroid -- distance between the two cluster centers</li>
</ul>
</li>
<li>Where to cut the dendrogram/how many clusters to choose
<ul>
<li>Can use same methods as k-means</li>
<li>Can also look at dendrogram and see if an obvious location exists based on distances between clusters</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Online</p>
</li>
<li>
<p>Unique attributes</p>
<ul>
<li>Unlike k-means, increasing the number of clusters in hierarchical clustering doesn't really "change" the clustering results, it just splits an existing cluster into two.</li>
<li>No need to pre-specify number of clusters, can be chosen after dendrogram is built.</li>
<li>Requires quantitative data</li>
</ul>
</li>
<li>
<p>Special use cases</p>
<ul>
<li>Most common and most studied form is agglomerative clustering, as discussed here. Can also do divisive clustering, where we start with one big cluster and recursively split. This can work better if the goal is relatively few clusters. (ESL 526)</li>
</ul>
</li>
</ul>
<h2><a id="user-content-other-good-resources" class="anchor" aria-hidden="true" href="#other-good-resources"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Other Good Resources</h2>
<ul>
<li><a href="https://class.coursera.org/ml-005/lecture" rel="nofollow">https://class.coursera.org/ml-005/lecture</a> (Week X)</li>
</ul>
</article>
  </div>

    </div>

  

  <details class="details-reset details-overlay details-overlay-dark">
    <summary data-hotkey="l" aria-label="Jump to line"></summary>
    <details-dialog class="Box Box--overlay d-flex flex-column anim-fade-in fast linejump" aria-label="Jump to line">
      <!-- '"` --><!-- </textarea></xmp> --></option></form><form class="js-jump-to-line-form Box-body d-flex" action="" accept-charset="UTF-8" method="get"><input name="utf8" type="hidden" value="&#x2713;" />
        <input class="form-control flex-auto mr-3 linejump-input js-jump-to-line-field" type="text" placeholder="Jump to line&hellip;" aria-label="Jump to line" autofocus>
        <button type="submit" class="btn" data-close-dialog>Go</button>
</form>    </details-dialog>
  </details>

    <div class="Popover anim-scale-in js-tagsearch-popover"
     hidden
     data-tagsearch-url="/GalvanizeDataScience/interview-prep/find-symbols"
     data-tagsearch-ref="master"
     data-tagsearch-path="review/Model_Comparison_Guide.md"
     data-tagsearch-lang="Markdown"
     data-hydro-click="{&quot;event_type&quot;:&quot;code_navigation.click_on_symbol&quot;,&quot;payload&quot;:{&quot;action&quot;:&quot;click_on_symbol&quot;,&quot;repository_id&quot;:26934610,&quot;ref&quot;:&quot;master&quot;,&quot;client_id&quot;:&quot;1814175083.1566936942&quot;,&quot;originating_request_id&quot;:&quot;6009:9A74:2DFC5:43931:5D659AA5&quot;,&quot;originating_url&quot;:&quot;https://github.com/GalvanizeDataScience/interview-prep/blob/master/review/Model_Comparison_Guide.md&quot;,&quot;referrer&quot;:&quot;https://github.com/GalvanizeDataScience/interview-prep/tree/master/review&quot;,&quot;user_id&quot;:8853113}}"
     data-hydro-click-hmac="9f48589787d4240c3d407ebe6b524fd6ed20200b38290f141ccfa41ca433ad73">
  <div class="Popover-message Popover-message--large Popover-message--top-left TagsearchPopover mt-1 mb-4 mx-auto Box box-shadow-large">
    <div class="TagsearchPopover-content js-tagsearch-popover-content overflow-auto" style="will-change:transform;">
    </div>
  </div>
</div>



  </div>
</div>

    </main>
  </div>
  

  </div>

        
<div class="footer container-lg width-full p-responsive" role="contentinfo">
  <div class="position-relative d-flex flex-row-reverse flex-lg-row flex-wrap flex-lg-nowrap flex-justify-center flex-lg-justify-between pt-6 pb-2 mt-6 f6 text-gray border-top border-gray-light ">
    <ul class="list-style-none d-flex flex-wrap col-12 col-lg-5 flex-justify-center flex-lg-justify-between mb-2 mb-lg-0">
      <li class="mr-3 mr-lg-0">&copy; 2019 <span title="0.78363s from unicorn-55876d589b-s47ch">GitHub</span>, Inc.</li>
        <li class="mr-3 mr-lg-0"><a data-ga-click="Footer, go to terms, text:terms" href="https://github.com/site/terms">Terms</a></li>
        <li class="mr-3 mr-lg-0"><a data-ga-click="Footer, go to privacy, text:privacy" href="https://github.com/site/privacy">Privacy</a></li>
        <li class="mr-3 mr-lg-0"><a data-ga-click="Footer, go to security, text:security" href="https://github.com/security">Security</a></li>
        <li class="mr-3 mr-lg-0"><a href="https://githubstatus.com/" data-ga-click="Footer, go to status, text:status">Status</a></li>
        <li><a data-ga-click="Footer, go to help, text:help" href="https://help.github.com">Help</a></li>
    </ul>

    <a aria-label="Homepage" title="GitHub" class="footer-octicon d-none d-lg-block mx-lg-4" href="https://github.com">
      <svg height="24" class="octicon octicon-mark-github" viewBox="0 0 16 16" version="1.1" width="24" aria-hidden="true"><path fill-rule="evenodd" d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0 0 16 8c0-4.42-3.58-8-8-8z"/></svg>
</a>
   <ul class="list-style-none d-flex flex-wrap col-12 col-lg-5 flex-justify-center flex-lg-justify-between mb-2 mb-lg-0">
        <li class="mr-3 mr-lg-0"><a data-ga-click="Footer, go to contact, text:contact" href="https://github.com/contact">Contact GitHub</a></li>
        <li class="mr-3 mr-lg-0"><a href="https://github.com/pricing" data-ga-click="Footer, go to Pricing, text:Pricing">Pricing</a></li>
      <li class="mr-3 mr-lg-0"><a href="https://developer.github.com" data-ga-click="Footer, go to api, text:api">API</a></li>
      <li class="mr-3 mr-lg-0"><a href="https://training.github.com" data-ga-click="Footer, go to training, text:training">Training</a></li>
        <li class="mr-3 mr-lg-0"><a href="https://github.blog" data-ga-click="Footer, go to blog, text:blog">Blog</a></li>
        <li><a data-ga-click="Footer, go to about, text:about" href="https://github.com/about">About</a></li>

    </ul>
  </div>
  <div class="d-flex flex-justify-center pb-6">
    <span class="f6 text-gray-light"></span>
  </div>
</div>



  <div id="ajax-error-message" class="ajax-error-message flash flash-error">
    <svg class="octicon octicon-alert" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"/></svg>
    <button type="button" class="flash-close js-ajax-error-dismiss" aria-label="Dismiss error">
      <svg class="octicon octicon-x" viewBox="0 0 12 16" version="1.1" width="12" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.48 8l3.75 3.75-1.48 1.48L6 9.48l-3.75 3.75-1.48-1.48L4.52 8 .77 4.25l1.48-1.48L6 6.52l3.75-3.75 1.48 1.48L7.48 8z"/></svg>
    </button>
    You can‚Äôt perform that action at this time.
  </div>


    
    <script crossorigin="anonymous" integrity="sha512-PFVbVSrMzusC1KLktzYYs16Ba4eiYgpG36jTWt0rbtvacsmX/QQFl+5ecqimZTvUKg8qbgeqGqVon2cTYh4Nvw==" type="application/javascript" src="https://github.githubassets.com/assets/frameworks-b1c626a0.js"></script>
    
    <script crossorigin="anonymous" async="async" integrity="sha512-w5sS5Hqgo7zwp/tCq1kOuj1QDDmqRusbQqY3s5+uPyJxu5nyEQrsUfgk04YKmG/li+8NlH9CazkCl+mRUn/4NQ==" type="application/javascript" src="https://github.githubassets.com/assets/github-bootstrap-927d0377.js"></script>
    
    
    
  <div class="js-stale-session-flash stale-session-flash flash flash-warn flash-banner" hidden
    >
    <svg class="octicon octicon-alert" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"/></svg>
    <span class="signed-in-tab-flash">You signed in with another tab or window. <a href="">Reload</a> to refresh your session.</span>
    <span class="signed-out-tab-flash">You signed out in another tab or window. <a href="">Reload</a> to refresh your session.</span>
  </div>
  <template id="site-details-dialog">
  <details class="details-reset details-overlay details-overlay-dark lh-default text-gray-dark hx_rsm" open>
    <summary role="button" aria-label="Close dialog"></summary>
    <details-dialog class="Box Box--overlay d-flex flex-column anim-fade-in fast hx_rsm-dialog hx_rsm-modal">
      <button class="Box-btn-octicon m-0 btn-octicon position-absolute right-0 top-0" type="button" aria-label="Close dialog" data-close-dialog>
        <svg class="octicon octicon-x" viewBox="0 0 12 16" version="1.1" width="12" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.48 8l3.75 3.75-1.48 1.48L6 9.48l-3.75 3.75-1.48-1.48L4.52 8 .77 4.25l1.48-1.48L6 6.52l3.75-3.75 1.48 1.48L7.48 8z"/></svg>
      </button>
      <div class="octocat-spinner my-6 js-details-dialog-spinner"></div>
    </details-dialog>
  </details>
</template>

  <div class="Popover js-hovercard-content position-absolute" style="display: none; outline: none;" tabindex="0">
  <div class="Popover-message Popover-message--bottom-left Popover-message--large Box box-shadow-large" style="width:360px;">
  </div>
</div>

  <div aria-live="polite" class="js-global-screen-reader-notice sr-only"></div>

  </body>
</html>

